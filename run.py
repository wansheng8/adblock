#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AdBlock è§„åˆ™é›†åˆå™¨ - ç¾åŒ–ç‰ˆ
è‡ªåŠ¨ä»å¤šä¸ªæºæ”¶é›†å¹¿å‘Šè¿‡æ»¤è§„åˆ™ï¼Œåˆå¹¶å»é‡åç”Ÿæˆç»Ÿä¸€çš„è¿‡æ»¤è§„åˆ™æ–‡ä»¶
"""

import os
import re
import time
import requests
import threading
import queue
from datetime import datetime, timedelta, timezone
from typing import List, Set, Dict, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import urllib3
import hashlib
import gzip
import json

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class AdBlockRuleCollector:
    def __init__(self):
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        self.sources_dir = os.path.join(self.base_dir, "rules", "sources")
        self.outputs_dir = os.path.join(self.base_dir, "rules", "outputs")
        self.white_sources_file = os.path.join(self.sources_dir, "white.txt")
        self.black_sources_file = os.path.join(self.sources_dir, "black.txt")
        self.output_file = os.path.join(self.outputs_dir, "adblock.txt")
        self.stats_file = os.path.join(self.outputs_dir, "stats.json")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.sources_dir, exist_ok=True)
        os.makedirs(self.outputs_dir, exist_ok=True)
        
        # ç”¨æˆ·ä»£ç†
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        # è§„åˆ™ç»Ÿè®¡
        self.stats = {
            'white_rules': 0,
            'black_rules': 0,
            'total_rules': 0,
            'sources_processed': 0,
            'sources_failed': 0,
            'duplicate_removed': 0,
        }
        
        # å†…å­˜ä¼˜åŒ–
        self.white_rules_hashes = set()
        self.black_rules_hashes = set()
        self.lock = threading.Lock()
        
        # ä¸´æ—¶æ–‡ä»¶å­˜å‚¨
        self.temp_dir = os.path.join(self.base_dir, "temp")
        os.makedirs(self.temp_dir, exist_ok=True)
    
    def load_sources(self, source_type: str) -> List[Tuple[str, str]]:
        """åŠ è½½è§„åˆ™æºURLåˆ—è¡¨"""
        source_file = self.white_sources_file if source_type == 'white' else self.black_sources_file
        
        if not os.path.exists(source_file):
            default_sources = self._get_default_sources(source_type)
            with open(source_file, 'w', encoding='utf-8') as f:
                for name, url in default_sources:
                    f.write(f"{name} {url}\n")
            return default_sources
        
        sources = []
        with open(source_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    parts = line.split(maxsplit=1)
                    if len(parts) == 2:
                        name, url = parts
                        sources.append((name.strip(), url.strip()))
                    else:
                        url = line
                        name = self._extract_name_from_url(url)
                        sources.append((name, url))
        return sources
    
    def _extract_name_from_url(self, url: str) -> str:
        """ä»URLæå–åç§°"""
        if '://' in url:
            url = url.split('://')[1]
        
        name = url.replace('raw.githubusercontent.com/', '') \
                 .replace('github.com/', '') \
                 .replace('easylist-downloads.adblockplus.org/', '') \
                 .replace('easylist.to/', '') \
                 .replace('secure.fanboy.co.nz/', '')
        
        if len(name) > 50:
            name = name[:50] + "..."
        
        return name
    
    def _get_default_sources(self, source_type: str) -> List[Tuple[str, str]]:
        """è·å–é»˜è®¤è§„åˆ™æº"""
        if source_type == 'white':
            return [
                ("Annoyances", "https://raw.githubusercontent.com/AdguardTeam/FiltersRegistry/master/filters/filter_14_Annoyances/filter.txt"),
                ("EasyList China", "https://easylist-downloads.adblockplus.org/easylistchina.txt"),
            ]
        else:
            return [
                ("AdGuard Base", "https://raw.githubusercontent.com/AdguardTeam/AdguardFilters/master/BaseFilter/sections/adservers.txt"),
                ("EasyList", "https://easylist.to/easylist/easylist.txt"),
                ("Anti-AD", "https://raw.githubusercontent.com/privacy-protection-tools/anti-AD/master/anti-ad-easylist.txt"),
            ]
    
    def fetch_rules(self, source_name: str, url: str, source_type: str) -> Dict:
        """ä»URLè·å–è§„åˆ™"""
        temp_file = os.path.join(self.temp_dir, f"{hashlib.md5(url.encode()).hexdigest()}.txt")
        
        try:
            # ç¼“å­˜æ£€æŸ¥
            if os.path.exists(temp_file):
                file_age = time.time() - os.path.getmtime(temp_file)
                if file_age < 3600:
                    with open(temp_file, 'r', encoding='utf-8') as f:
                        rules = [line.strip() for line in f if line.strip()]
                    
                    with self.lock:
                        if source_type == 'white':
                            self.stats['white_rules'] += len(rules)
                        else:
                            self.stats['black_rules'] += len(rules)
                        self.stats['sources_processed'] += 1
                    
                    print(f"âœ“ ä»ç¼“å­˜è¯»å–: {source_name} ({len(rules)} æ¡è§„åˆ™)")
                    return {'name': source_name, 'url': url, 'count': len(rules), 'rules': rules}
            
            # ç½‘ç»œè·å–
            print(f"æ­£åœ¨è·å–: {source_name}")
            response = requests.get(url, headers=self.headers, timeout=60, verify=False)
            response.raise_for_status()
            
            rules = []
            for line in response.text.splitlines():
                line = line.strip()
                if self._is_valid_rule(line):
                    rule_hash = hashlib.md5(line.encode()).hexdigest()
                    
                    with self.lock:
                        if source_type == 'white':
                            if rule_hash in self.white_rules_hashes:
                                self.stats['duplicate_removed'] += 1
                                continue
                            self.white_rules_hashes.add(rule_hash)
                        else:
                            if rule_hash in self.black_rules_hashes:
                                self.stats['duplicate_removed'] += 1
                                continue
                            self.black_rules_hashes.add(rule_hash)
                    
                    rules.append(line)
            
            # ä¿å­˜ç¼“å­˜
            with open(temp_file, 'w', encoding='utf-8') as f:
                for rule in rules:
                    f.write(rule + '\n')
            
            with self.lock:
                if source_type == 'white':
                    self.stats['white_rules'] += len(rules)
                else:
                    self.stats['black_rules'] += len(rules)
                self.stats['sources_processed'] += 1
            
            print(f"âœ“ æˆåŠŸè·å–: {source_name} ({len(rules)} æ¡è§„åˆ™)")
            return {'name': source_name, 'url': url, 'count': len(rules), 'rules': rules}
            
        except Exception as e:
            with self.lock:
                self.stats['sources_failed'] += 1
            print(f"âœ— è·å–å¤±è´¥: {source_name} - {str(e)}")
            return {'name': source_name, 'url': url, 'count': 0, 'rules': [], 'error': str(e)}
    
    def _is_valid_rule(self, rule: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å¹¿å‘Šè¿‡æ»¤è§„åˆ™"""
        if not rule or len(rule) > 1000:
            return False
        
        if rule.startswith('!') or rule.startswith('[') or rule.startswith('#'):
            return False
        
        if '##' in rule:
            return True
        
        if rule.startswith('||') or rule.startswith('@@'):
            return True
        
        if '^' in rule or '$' in rule:
            return True
        
        return False
    
    def process_and_write_rules(self, all_rules_data: List[Dict]):
        """å¤„ç†å’Œå†™å…¥è§„åˆ™æ–‡ä»¶"""
        print("\nâš™ï¸ å¤„ç†å’Œåˆå¹¶è§„åˆ™...")
        
        white_rules = []
        black_rules = []
        
        for source_data in all_rules_data:
            if 'rules' in source_data:
                for rule in source_data['rules']:
                    if rule.startswith('@@'):
                        white_rules.append(rule)
                    else:
                        black_rules.append(rule)
        
        white_rules = list(dict.fromkeys(white_rules))
        black_rules = list(dict.fromkeys(black_rules))
        
        final_rules = []
        final_rules.extend(white_rules)
        final_rules.extend(black_rules)
        
        self.stats['total_rules'] = len(final_rules)
        
        print(f"ç™½åå•è§„åˆ™: {len(white_rules)} æ¡")
        print(f"é»‘åå•è§„åˆ™: {len(black_rules)} æ¡")
        print(f"æ€»è§„åˆ™æ•°: {len(final_rules)} æ¡")
        
        # ç”Ÿæˆè§„åˆ™æ–‡ä»¶å¤´
        shanghai_tz = timezone(timedelta(hours=8))
        update_time = datetime.now(shanghai_tz).strftime('%Y-%m-%d %H:%M:%S')
        
        file_header = f"""! Title: AdBlock ç»¼åˆè¿‡æ»¤è§„åˆ™
! Description: ç²¾å‡†è¶…çº§æ™ºèƒ½å¹¿å‘Šè¿‡æ»¤è§„åˆ™é›†åˆå™¨
! Version: {datetime.now().strftime('%Y%m%d')}
! TimeUpdated: {update_time} (ä¸Šæµ·æ—¶é—´)
! Homepage: https://github.com/wansheng8/adblock
! Expires: 1 days
! Total rules: {len(final_rules)}
!
"""
        
        # å†™å…¥æ··åˆè§„åˆ™æ–‡ä»¶
        print(f"\nğŸ’¾ å†™å…¥è§„åˆ™æ–‡ä»¶...")
        
        batch_size = 50000
        with open(self.output_file, 'w', encoding='utf-8') as f:
            f.write(file_header)
            
            for i in range(0, len(final_rules), batch_size):
                batch = final_rules[i:i + batch_size]
                for rule in batch:
                    f.write(rule + '\n')
        
        # å†™å…¥å‹ç¼©ç‰ˆæœ¬
        try:
            with open(self.output_file, 'rb') as f_in:
                with gzip.open(self.output_file + '.gz', 'wb') as f_out:
                    f_out.writelines(f_in)
            print(f"âœ“ å·²åˆ›å»ºå‹ç¼©ç‰ˆæœ¬")
        except Exception as e:
            print(f"âœ— åˆ›å»ºå‹ç¼©ç‰ˆæœ¬å¤±è´¥: {e}")
        
        # å†™å…¥å•ç‹¬çš„è§„åˆ™æ–‡ä»¶
        with open(os.path.join(self.outputs_dir, "white_only.txt"), 'w', encoding='utf-8') as f:
            f.write("! ä»…ç™½åå•è§„åˆ™\n")
            for rule in white_rules:
                f.write(rule + '\n')
        
        with open(os.path.join(self.outputs_dir, "black_only.txt"), 'w', encoding='utf-8') as f:
            f.write("! ä»…é»‘åå•è§„åˆ™\n")
            for rule in black_rules:
                f.write(rule + '\n')
        
        # å†™å…¥ç»Ÿè®¡æ–‡ä»¶
        with open(self.stats_file, 'w', encoding='utf-8') as f:
            json.dump(self.stats, f, ensure_ascii=False, indent=2)
    
    def generate_readme(self, all_rules_data: List[Dict]) -> str:
        """ç”Ÿæˆç¾åŒ–çš„README.mdæ–‡ä»¶ - åªæœ‰ä¸‰ä¸ªéƒ¨åˆ†"""
        # è·å–ä¸Šæµ·æ—¶é—´
        shanghai_tz = timezone(timedelta(hours=8))
        update_time = datetime.now(shanghai_tz).strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
        total_rules = self.stats['total_rules']
        
        # ç¬¬ä¸€éƒ¨åˆ†ï¼šåç§°ä»‹ç»
        intro = f"""# ğŸš€ AdBlock è¶…çº§æ™ºèƒ½å¹¿å‘Šè¿‡æ»¤è§„åˆ™

<div align="center">

## ç²¾å‡† â€¢ æ™ºèƒ½ â€¢ é«˜æ•ˆ â€¢ è‡ªåŠ¨æ›´æ–°

**ä¸€ä¸ªè‡ªåŠ¨æ”¶é›†ã€åˆå¹¶å’Œä¼˜åŒ–å¤šæºå¹¿å‘Šè¿‡æ»¤è§„åˆ™çš„æ™ºèƒ½å·¥å…·é›†åˆå™¨**

âœ¨ **æ ¸å¿ƒç‰¹æ€§** âœ¨

- ğŸ›¡ï¸ **å…¨é¢é˜²æŠ¤**: å¹¿å‘Šæ‹¦æˆªã€éšç§ä¿æŠ¤ã€æ¶æ„ç½‘ç«™é˜²æŠ¤
- âš¡ **æ™ºèƒ½ä¼˜åŒ–**: è‡ªåŠ¨å»é‡ã€è§„åˆ™åˆ†ç±»ã€æ€§èƒ½ä¼˜åŒ–
- ğŸ”„ **è‡ªåŠ¨æ›´æ–°**: æ¯æ—¥è‡ªåŠ¨åŒæ­¥æœ€æ–°è§„åˆ™æº
- ğŸ“Š **è§„åˆ™ä¸°å¯Œ**: å½“å‰åŒ…å« **{total_rules:,}** æ¡è¿‡æ»¤è§„åˆ™
- ğŸ¯ **ç²¾å‡†è¿‡æ»¤**: å…ƒç´ éšè—ã€åŸŸåæ‹¦æˆªã€å¼¹çª—å±è”½ã€åˆ†æå·¥å…·æ‹¦æˆª

</div>
"""
        
        # ç¬¬äºŒéƒ¨åˆ†ï¼šè®¢é˜…é“¾æ¥ï¼ˆç¾åŒ–è¡¨æ ¼ï¼‰
        subscriptions = """## ğŸ“¥ è®¢é˜…é“¾æ¥

<div align="center">

| è§„åˆ™ç±»å‹ | è¯´æ˜ | è®¢é˜…é“¾æ¥ |
|:---|:---|:---|
| ğŸ¯ **æ··åˆè§„åˆ™** | å®Œæ•´è¿‡æ»¤è§„åˆ™é›†<br>ï¼ˆç™½åå•åœ¨å‰ï¼Œé»‘åå•åœ¨åï¼‰ | [`adblock.txt`](https://raw.githubusercontent.com/wansheng8/adblock/main/rules/outputs/adblock.txt) |
| ğŸ—œï¸ **å‹ç¼©ç‰ˆæœ¬** | GZIPå‹ç¼©æ ¼å¼<br>èŠ‚çœæµé‡ï¼ŒåŠ è½½æ›´å¿« | [`adblock.txt.gz`](https://raw.githubusercontent.com/wansheng8/adblock/main/rules/outputs/adblock.txt.gz) |
| âš« **ä»…é»‘åå•** | åªåŒ…å«æ‹¦æˆªè§„åˆ™<br>ï¼ˆå¹¿å‘ŠåŸŸåã€è·Ÿè¸ªå™¨ç­‰ï¼‰ | [`black_only.txt`](https://raw.githubusercontent.com/wansheng8/adblock/main/rules/outputs/black_only.txt) |
| âšª **ä»…ç™½åå•** | åªåŒ…å«æ”¾è¡Œè§„åˆ™<br>ï¼ˆè¯¯æ‹¦æˆªä¿®å¤ã€å¿…è¦åŠŸèƒ½ï¼‰ | [`white_only.txt`](https://raw.githubusercontent.com/wansheng8/adblock/main/rules/outputs/white_only.txt) |

</div>

<div align="center">

**ğŸ’¡ ä½¿ç”¨å»ºè®®**: æ™®é€šç”¨æˆ·æ¨èä½¿ç”¨ **æ··åˆè§„åˆ™**ï¼Œä¸“ä¸šç”¨æˆ·å¯æ ¹æ®éœ€è¦é€‰æ‹©å…¶ä»–ç‰ˆæœ¬

</div>
"""
        
        # ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ›´æ–°æ—¶é—´
        update_time_section = f"""## ğŸ• æœ€æ–°æ›´æ–°æ—¶é—´

<div align="center">

### ğŸ¯ æœ€åæ›´æ–°æ—¶é—´

**{update_time}** (ä¸Šæµ·æ—¶é—´)

---

### ğŸ“Š æ›´æ–°çŠ¶æ€

![è§„åˆ™æ€»æ•°](https://img.shields.io/badge/è§„åˆ™æ€»æ•°-{total_rules:,}-blue)
![æ›´æ–°æ—¶é—´](https://img.shields.io/badge/æœ€åæ›´æ–°-{update_time.split()[0]}-green)
![è‡ªåŠ¨æ›´æ–°](https://img.shields.io/badge/è‡ªåŠ¨æ›´æ–°-å·²å¯ç”¨-success)

</div>

<div align="center">

*âœ¨ è§„åˆ™æ¯æ—¥è‡ªåŠ¨æ›´æ–°ï¼Œç¡®ä¿å¹¿å‘Šè¿‡æ»¤æ•ˆæœå§‹ç»ˆæœ€ä½³ âœ¨*

</div>
"""
        
        # ç»„åˆä¸‰ä¸ªéƒ¨åˆ†
        readme_content = f"""{intro}

{subscriptions}

{update_time_section}
"""
        
        return readme_content
    
    def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        print("=" * 70)
        print("ğŸ›¡ï¸  AdBlock è§„åˆ™é›†åˆå™¨ - ç¾åŒ–ç‰ˆ")
        print("=" * 70)
        
        self._cleanup_temp_files()
        
        # åŠ è½½æº
        print("\nğŸ“ åŠ è½½è§„åˆ™æº...")
        white_sources = self.load_sources('white')
        black_sources = self.load_sources('black')
        
        print(f"ç™½åå•æº: {len(white_sources)} ä¸ª")
        print(f"é»‘åå•æº: {len(black_sources)} ä¸ª")
        
        # å¤šçº¿ç¨‹è·å–è§„åˆ™
        print("\nğŸŒ å¼€å§‹è·å–è§„åˆ™...")
        all_rules_data = []
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = []
            
            for name, url in white_sources:
                futures.append(executor.submit(self.fetch_rules, name, url, 'white'))
            
            for name, url in black_sources:
                futures.append(executor.submit(self.fetch_rules, name, url, 'black'))
            
            completed = 0
            total = len(futures)
            
            for future in as_completed(futures):
                try:
                    result = future.result()
                    all_rules_data.append(result)
                    completed += 1
                    print(f"è¿›åº¦: {completed}/{total}")
                except Exception as e:
                    print(f"ä»»åŠ¡æ‰§è¡Œé”™è¯¯: {e}")
                    completed += 1
        
        # å¤„ç†å¹¶å†™å…¥è§„åˆ™
        self.process_and_write_rules(all_rules_data)
        
        # ç”ŸæˆREADME
        print("\nğŸ“„ ç”ŸæˆREADME.md...")
        readme_content = self.generate_readme(all_rules_data)
        
        try:
            with open(os.path.join(self.base_dir, "README.md"), 'w', encoding='utf-8') as f:
                f.write(readme_content)
            print("âœ… README.md ç”ŸæˆæˆåŠŸ")
        except Exception as e:
            print(f"âŒ ç”ŸæˆREADME.mdå¤±è´¥: {e}")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print("\n" + "=" * 70)
        print("ğŸ‰ æ‰§è¡Œå®Œæˆï¼")
        print("=" * 70)
        print(f"ğŸ“Š æ€»è§„åˆ™æ•°: {self.stats['total_rules']:,}")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶å·²ç”Ÿæˆ")
        print("=" * 70)
    
    def _cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            for filename in os.listdir(self.temp_dir):
                filepath = os.path.join(self.temp_dir, filename)
                if os.path.isfile(filepath):
                    file_age = time.time() - os.path.getmtime(filepath)
                    if file_age > 86400:
                        os.remove(filepath)
        except:
            pass

def main():
    """ä¸»å‡½æ•°"""
    try:
        collector = AdBlockRuleCollector()
        collector.run()
        return 0
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
