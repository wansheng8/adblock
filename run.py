#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¹¿å‘Šè¿‡æ»¤è§„åˆ™ç”Ÿæˆå™¨ - å¢å¼ºæ‹¦æˆªæ•ˆæœç‰ˆ
"""

import os
import re
import json
import time
import concurrent.futures
from datetime import datetime, timedelta
from typing import Set, List, Tuple, Optional
import requests

# é…ç½®ä¿¡æ¯
CONFIG = {
    'GITHUB_USER': 'wansheng8',
    'GITHUB_REPO': 'adblock',
    'GITHUB_BRANCH': 'main',
    'MAX_WORKERS': 8,
    'TIMEOUT': 20,
    'RETRY': 3,
    'BLACK_SOURCE': 'rules/sources/black.txt',
    'WHITE_SOURCE': 'rules/sources/white.txt',
    'STRONG_AD_DOMAINS': {  # å¼ºåŒ–æ‹¦æˆªçš„å¹¿å‘ŠåŸŸå
        'doubleclick.net', 'google-analytics.com', 'googlesyndication.com',
        'googleadservices.com', 'adservice.google.com', 'ads.google.com',
        'adzerk.net', 'amazon-adsystem.com', 'scorecardresearch.com',
        'outbrain.com', 'taboola.com', 'criteo.com', 'adsrvr.org',
        'adnxs.com', 'casalemedia.com', 'rlcdn.com'
    }
}

class EnhancedAdBlockGenerator:
    def __init__(self):
        self.black_domains = set()      # æœ€ç»ˆé»‘åå•åŸŸå
        self.white_domains = set()      # ç™½åå•åŸŸå
        self.black_rules = set()        # å¤æ‚é»‘åå•è§„åˆ™
        self.white_rules = set()        # å¤æ‚ç™½åå•è§„åˆ™
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_rules_processed': 0,
            'domains_extracted': 0,
            'complex_rules_saved': 0
        }
        
        # åˆ›å»ºç›®å½•
        os.makedirs('rules/sources', exist_ok=True)
        os.makedirs('rules/outputs', exist_ok=True)
        
        # åˆ›å»ºé»˜è®¤è§„åˆ™æº
        self.create_default_sources()
    
    def create_default_sources(self):
        """åˆ›å»ºé»˜è®¤è§„åˆ™æºæ–‡ä»¶"""
        # é»‘åå•æº - ä½¿ç”¨æ›´å¤šæœ‰æ•ˆçš„è§„åˆ™æº
        if not os.path.exists(CONFIG['BLACK_SOURCE']):
            with open(CONFIG['BLACK_SOURCE'], 'w', encoding='utf-8') as f:
                f.write("# å¹¿å‘Šè¿‡æ»¤è§„åˆ™æº - å¢å¼ºç‰ˆ\n")
                f.write("# æ¯è¡Œä¸€ä¸ªURL\n\n")
                f.write("# 1. AdGuardåŸºç¡€å¹¿å‘Šè§„åˆ™ï¼ˆæ ¸å¿ƒï¼‰\n")
                f.write("https://raw.githubusercontent.com/AdguardTeam/AdguardFilters/master/BaseFilter/sections/adservers.txt\n\n")
                f.write("# 2. EasyListè§„åˆ™ï¼ˆä¸»è¦è§„åˆ™ï¼‰\n")
                f.write("https://easylist.to/easylist/easylist.txt\n\n")
                f.write("# 3. EasyPrivacyè§„åˆ™ï¼ˆéšç§ä¿æŠ¤ï¼‰\n")
                f.write("https://easylist.to/easylist/easyprivacy.txt\n\n")
                f.write("# 4. ä¸­æ–‡å¹¿å‘Šè§„åˆ™\n")
                f.write("https://raw.githubusercontent.com/AdguardTeam/ChineseFilter/master/ADGUARD_FILTER.txt\n\n")
                f.write("# 5. Fanboy's Annoyance Listï¼ˆçƒ¦äººå†…å®¹ï¼‰\n")
                f.write("https://secure.fanboy.co.nz/fanboy-annoyance.txt\n\n")
                f.write("# 6. NoCoin Listï¼ˆæŒ–çŸ¿è„šæœ¬ï¼‰\n")
                f.write("https://raw.githubusercontent.com/hoshsadiq/adblock-nocoin-list/master/nocoin.txt\n\n")
                f.write("# 7. æ¶æ„è½¯ä»¶è¿‡æ»¤\n")
                f.write("https://raw.githubusercontent.com/DandelionSprout/adfilt/master/Alternate%20versions%20Anti-Malware%20List/AntiMalwareAdGuardHome.txt\n\n")
                f.write("# 8. AdGuard Tracking Protection\n")
                f.write("https://raw.githubusercontent.com/AdguardTeam/AdguardFilters/master/BaseFilter/sections/tracking.txt\n")
        
        # ç™½åå•æº - ä¿æŒç®€æ´
        if not os.path.exists(CONFIG['WHITE_SOURCE']):
            with open(CONFIG['WHITE_SOURCE'], 'w', encoding='utf-8') as f:
                f.write("# ç™½åå•è§„åˆ™æº\n")
                f.write("# åªåŒ…å«ä»¥@@å¼€å¤´çš„è§„åˆ™\n\n")
                f.write("# AdGuardç™½åå•\n")
                f.write("https://raw.githubusercontent.com/AdguardTeam/AdguardFilters/master/BaseFilter/sections/whitelist.txt\n\n")
                f.write("# é‡è¦ç½‘ç«™ç™½åå•\n")
                f.write("# @@||google.com^\n")
                f.write("# @@||github.com^\n")
    
    def download_content(self, url: str) -> Optional[str]:
        """ä¸‹è½½è§„åˆ™å†…å®¹"""
        for i in range(CONFIG['RETRY']):
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    'Accept': 'text/plain, */*',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Connection': 'keep-alive'
                }
                response = requests.get(url, headers=headers, timeout=CONFIG['TIMEOUT'])
                response.raise_for_status()
                return response.text
            except Exception as e:
                if i < CONFIG['RETRY'] - 1:
                    time.sleep(1)
                else:
                    print(f"  âŒ ä¸‹è½½å¤±è´¥ {url}: {str(e)[:100]}")
        return None
    
    def extract_domains_from_line(self, line: str) -> Tuple[List[str], bool, Optional[str]]:
        """ä»è§„åˆ™è¡Œä¸­æå–åŸŸåï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰"""
        line = line.strip()
        if not line:
            return [], False, None
        
        # è·³è¿‡æ³¨é‡Š
        if line.startswith('!') or line.startswith('#'):
            return [], False, None
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯ç™½åå•
        is_whitelist = line.startswith('@@')
        original_line = line
        
        # å¦‚æœæ˜¯ç™½åå•è§„åˆ™ï¼Œç§»é™¤@@å‰ç¼€
        if is_whitelist:
            line = line[2:]
        
        # å°è¯•åŒ¹é…å¸¸è§æ ¼å¼
        patterns = [
            # AdBlockæ ¼å¼
            (r'^\|\|([a-zA-Z0-9.-]+)\^', 1),          # ||domain.com^
            (r'^\|\|([a-zA-Z0-9.-]+)\/', 1),          # ||domain.com/
            (r'^([a-zA-Z0-9.-]+)\^$', 1),             # domain.com^
            (r'^\|\|([a-zA-Z0-9.-]+)\$', 1),          # ||domain.com$
            
            # åŸŸåæ ¼å¼
            (r'^([a-zA-Z0-9.-]+)$', 1),               # domain.com
            
            # Hostsæ ¼å¼
            (r'^\d+\.\d+\.\d+\.\d+\s+([a-zA-Z0-9.-]+)', 1),  # 0.0.0.0 domain.com
            
            # é€šé…ç¬¦æ ¼å¼
            (r'^\*\.([a-zA-Z0-9.-]+)', 1),            # *.domain.com
            
            # URLæ ¼å¼
            (r'^https?://([^/\$\^]+)', 1),            # http://domain.com
            (r'^//([^/\$\^]+)', 1),                   # //domain.com
            
            # å¤æ‚è§„åˆ™ä¸­çš„åŸŸå
            (r'domain=([a-zA-Z0-9.-]+)', 1),          # $domain=domain.com
            (r'([a-zA-Z0-9.-]+)\^?\$', 1),            # domain.com^$...
        ]
        
        domains = []
        for pattern, group in patterns:
            matches = re.findall(pattern, line)
            for match in matches:
                if isinstance(match, tuple):
                    domain = match[group-1]
                else:
                    domain = match
                
                domain = self.normalize_domain(domain)
                if self.is_valid_domain(domain):
                    domains.append(domain)
        
        # å»é‡
        domains = list(set(domains))
        
        return domains, is_whitelist, original_line if not domains else None
    
    def normalize_domain(self, domain: str) -> str:
        """æ ‡å‡†åŒ–åŸŸå"""
        if not domain:
            return ""
        
        domain = domain.lower().strip()
        
        # ç§»é™¤å¸¸è§å‰ç¼€
        prefixes = ['www.', '*.', 'm.']
        for prefix in prefixes:
            if domain.startswith(prefix):
                domain = domain[len(prefix):]
        
        # ç§»é™¤å¸¸è§åç¼€
        suffixes = ['.', '^', '$', '|', '~']
        for suffix in suffixes:
            if domain.endswith(suffix):
                domain = domain[:-len(suffix)]
        
        return domain
    
    def is_valid_domain(self, domain: str) -> bool:
        """æ£€æŸ¥åŸŸåæ˜¯å¦æœ‰æ•ˆ"""
        domain = self.normalize_domain(domain)
        
        if not domain or len(domain) > 253:
            return False
        
        # æ’é™¤æœ¬åœ°åŸŸå
        local_domains = {
            'localhost', 'local', 'broadcasthost',
            '0.0.0.0', '127.0.0.1', '::1',
            'ip6-localhost', 'ip6-loopback'
        }
        if domain in local_domains:
            return False
        
        # æ’é™¤IPåœ°å€
        if re.match(r'^\d+\.\d+\.\d+\.\d+$', domain):
            return False
        
        # æ£€æŸ¥åŸŸåæ ¼å¼
        parts = domain.split('.')
        if len(parts) < 2:
            return False
        
        # æ£€æŸ¥æ¯ä¸ªéƒ¨åˆ†
        for part in parts:
            if not part or len(part) > 63:
                return False
            if not re.match(r'^[a-z0-9]([a-z0-9\-]*[a-z0-9])?$', part):
                return False
        
        return True
    
    def process_rule_content(self, content: str, url: str):
        """å¤„ç†è§„åˆ™å†…å®¹"""
        lines_processed = 0
        domains_found = 0
        
        for line in content.split('\n'):
            lines_processed += 1
            self.stats['total_rules_processed'] += 1
            
            domains, is_whitelist, original_line = self.extract_domains_from_line(line)
            
            if domains:
                domains_found += len(domains)
                self.stats['domains_extracted'] += len(domains)
                
                if is_whitelist:
                    self.white_domains.update(domains)
                    # ä¿å­˜ç™½åå•è§„åˆ™
                    for domain in domains:
                        self.white_rules.add(f"@@||{domain}^")
                else:
                    self.black_domains.update(domains)
            
            # ä¿å­˜æ— æ³•æå–åŸŸåçš„å¤æ‚è§„åˆ™
            elif original_line and len(original_line.strip()) > 3:
                self.stats['complex_rules_saved'] += 1
                if is_whitelist:
                    self.white_rules.add(original_line)
                else:
                    # ä¿å­˜æœ‰æ•ˆçš„å¤æ‚è§„åˆ™
                    if re.search(r'[a-zA-Z0-9\/\$\^\|\*]', original_line):
                        self.black_rules.add(original_line)
        
        print(f"  âœ“ å¤„ç†å®Œæˆ: {lines_processed} è¡Œ, æå– {domains_found} ä¸ªåŸŸå")
    
    def process_url(self, url: str):
        """å¤„ç†å•ä¸ªè§„åˆ™æºURL"""
        print(f"  ğŸ“¥ å¤„ç†: {url}")
        content = self.download_content(url)
        if not content:
            return
        
        self.process_rule_content(content, url)
    
    def load_and_process_sources(self):
        """åŠ è½½å¹¶å¤„ç†æ‰€æœ‰è§„åˆ™æº"""
        print("ğŸ” åŠ è½½è§„åˆ™æº...")
        
        # è¯»å–æ‰€æœ‰è§„åˆ™æºURL
        urls = []
        
        # è¯»å–é»‘åå•æº
        if os.path.exists(CONFIG['BLACK_SOURCE']):
            with open(CONFIG['BLACK_SOURCE'], 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        urls.append(line)
        
        # è¯»å–ç™½åå•æº
        if os.path.exists(CONFIG['WHITE_SOURCE']):
            with open(CONFIG['WHITE_SOURCE'], 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        urls.append(line)
        
        if not urls:
            print("  âš ï¸ æœªæ‰¾åˆ°è§„åˆ™æºURL")
            return
        
        print(f"  æ‰¾åˆ° {len(urls)} ä¸ªè§„åˆ™æº")
        
        # å¹¶è¡Œå¤„ç†æ‰€æœ‰è§„åˆ™æº
        with concurrent.futures.ThreadPoolExecutor(max_workers=CONFIG['MAX_WORKERS']) as executor:
            futures = []
            for url in urls:
                future = executor.submit(self.process_url, url)
                futures.append(future)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            completed = 0
            for future in concurrent.futures.as_completed(futures):
                try:
                    future.result(timeout=30)
                    completed += 1
                    print(f"  âœ… [{completed}/{len(urls)}] å®Œæˆ")
                except Exception as e:
                    print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
        
        print(f"âœ… è§£æå®Œæˆ:")
        print(f"   é»‘åå•åŸŸå: {len(self.black_domains):,} ä¸ª")
        print(f"   ç™½åå•åŸŸå: {len(self.white_domains):,} ä¸ª")
        print(f"   å¤æ‚è§„åˆ™: é»‘åå• {len(self.black_rules):,} æ¡, ç™½åå• {len(self.white_rules):,} æ¡")
    
    def enhance_ad_domains(self):
        """å¼ºåŒ–å¹¿å‘ŠåŸŸåæ‹¦æˆª"""
        print("ğŸ›¡ï¸  å¼ºåŒ–å¹¿å‘ŠåŸŸåæ‹¦æˆª...")
        
        original_count = len(self.black_domains)
        
        # æ·»åŠ å¼ºåŒ–çš„å¹¿å‘ŠåŸŸå
        for domain in CONFIG['STRONG_AD_DOMAINS']:
            if domain not in self.white_domains:
                self.black_domains.add(domain)
        
        added = len(self.black_domains) - original_count
        if added > 0:
            print(f"  æ·»åŠ  {added} ä¸ªå¼ºåŒ–å¹¿å‘ŠåŸŸå")
    
    def apply_intelligent_whitelist(self):
        """æ™ºèƒ½ç™½åå•å¤„ç†"""
        print("ğŸ¤” åº”ç”¨æ™ºèƒ½ç™½åå•...")
        
        original_count = len(self.black_domains)
        
        # åªç§»é™¤å®Œå…¨åŒ¹é…çš„ç™½åå•åŸŸåï¼ˆå®‰å…¨æ“ä½œï¼‰
        domains_to_remove = set()
        for white_domain in self.white_domains:
            if white_domain in self.black_domains:
                domains_to_remove.add(white_domain)
        
        self.black_domains -= domains_to_remove
        
        removed = original_count - len(self.black_domains)
        if removed > 0:
            print(f"  å®‰å…¨ç§»é™¤ {removed} ä¸ªç™½åå•åŸŸå")
    
    def generate_optimized_files(self):
        """ç”Ÿæˆä¼˜åŒ–çš„è§„åˆ™æ–‡ä»¶"""
        print("ğŸ“ ç”Ÿæˆè§„åˆ™æ–‡ä»¶...")
        
        # è·å–æ—¶é—´
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        version = datetime.now().strftime('%Y%m%d')
        
        # å¯¹åŸŸåæ’åº
        sorted_black_domains = sorted(self.black_domains)
        
        # 1. ç”Ÿæˆä¼˜åŒ–çš„ad.txt
        with open('rules/outputs/ad.txt', 'w', encoding='utf-8') as f:
            f.write(f"! å¹¿å‘Šè¿‡æ»¤è§„åˆ™ - å¢å¼ºç‰ˆ v{version}\n")
            f.write(f"! æ›´æ–°æ—¶é—´: {timestamp}\n")
            f.write(f"! åŸŸåæ•°é‡: {len(self.black_domains):,} ä¸ª\n")
            f.write(f"! è§„åˆ™æ•°é‡: {len(self.black_rules):,} æ¡\n")
            f.write(f"! å¼ºåŒ–å¹¿å‘ŠåŸŸå: {len(CONFIG['STRONG_AD_DOMAINS'])} ä¸ª\n")
            f.write("!\n\n")
            
            # ç™½åå•è§„åˆ™
            if self.white_rules:
                f.write("! ====== ç™½åå•è§„åˆ™ ======\n")
                for rule in sorted(self.white_rules):
                    if rule.startswith('@@'):
                        f.write(f"{rule}\n")
                f.write("\n")
            
            # æ ¸å¿ƒå¹¿å‘ŠåŸŸåï¼ˆå¼ºåŒ–æ‹¦æˆªçš„ï¼‰
            f.write("! ====== æ ¸å¿ƒå¹¿å‘ŠåŸŸå ======\n")
            for domain in sorted(CONFIG['STRONG_AD_DOMAINS']):
                if domain in self.black_domains:
                    f.write(f"||{domain}^\n")
            
            # å…¶ä»–å¹¿å‘ŠåŸŸå
            f.write("\n! ====== å…¶ä»–å¹¿å‘ŠåŸŸå ======\n")
            for domain in sorted_black_domains:
                if domain not in CONFIG['STRONG_AD_DOMAINS']:
                    f.write(f"||{domain}^\n")
            
            # å¤æ‚è§„åˆ™
            if self.black_rules:
                f.write("\n! ====== å¤æ‚æ‹¦æˆªè§„åˆ™ ======\n")
                for rule in sorted(self.black_rules):
                    if not rule.startswith('@@'):
                        f.write(f"{rule}\n")
        
        # 2. ç”Ÿæˆdns.txtï¼ˆåªåŒ…å«åŸŸåï¼‰
        with open('rules/outputs/dns.txt', 'w', encoding='utf-8') as f:
            f.write(f"# DNSå¹¿å‘Šè¿‡æ»¤è§„åˆ™ v{version}\n")
            f.write(f"# æ›´æ–°æ—¶é—´: {timestamp}\n")
            f.write(f"# åŸŸåæ•°é‡: {len(self.black_domains):,} ä¸ª\n")
            f.write("#\n\n")
            
            # åˆ†ç»„å†™å…¥ï¼Œæé«˜å¯è¯»æ€§
            batch_size = 1000
            for i in range(0, len(sorted_black_domains), batch_size):
                batch = sorted_black_domains[i:i+batch_size]
                if i > 0:
                    f.write("\n")
                for domain in batch:
                    f.write(f"{domain}\n")
        
        # 3. ç”Ÿæˆhosts.txt
        with open('rules/outputs/hosts.txt', 'w', encoding='utf-8') as f:
            f.write(f"# Hostså¹¿å‘Šè¿‡æ»¤è§„åˆ™ v{version}\n")
            f.write(f"# æ›´æ–°æ—¶é—´: {timestamp}\n")
            f.write(f"# åŸŸåæ•°é‡: {len(self.black_domains):,} ä¸ª\n")
            f.write("#\n\n")
            f.write("127.0.0.1 localhost\n")
            f.write("::1 localhost\n")
            f.write("#\n")
            f.write("# å¹¿å‘ŠåŸŸå\n\n")
            
            # åˆ†æ‰¹å†™å…¥
            batch_size = 500
            for i in range(0, len(sorted_black_domains), batch_size):
                batch = sorted_black_domains[i:i+batch_size]
                f.write(f"# åŸŸå {i+1}-{i+len(batch)}\n")
                for domain in batch:
                    f.write(f"0.0.0.0 {domain}\n")
                f.write("\n")
        
        # 4. ç”Ÿæˆè§„åˆ™ä¿¡æ¯
        info = {
            'version': version,
            'updated_at': timestamp,
            'statistics': {
                'total_processed_rules': self.stats['total_rules_processed'],
                'domains_extracted': self.stats['domains_extracted'],
                'complex_rules_saved': self.stats['complex_rules_saved'],
                'final_blacklist_domains': len(self.black_domains),
                'whitelist_domains': len(self.white_domains),
                'strong_ad_domains': len(CONFIG['STRONG_AD_DOMAINS'])
            }
        }
        
        with open('rules/outputs/info.json', 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)
        
        print("ğŸ“„ è§„åˆ™æ–‡ä»¶ç”Ÿæˆå®Œæˆ:")
        print(f"   ad.txt - AdBlockè§„åˆ™ ({len(self.black_domains):,}ä¸ªåŸŸå)")
        print(f"   dns.txt - DNSè§„åˆ™ ({len(self.black_domains):,}ä¸ªåŸŸå)")
        print(f"   hosts.txt - Hostsè§„åˆ™ ({len(self.black_domains):,}ä¸ªåŸŸå)")
        print(f"   info.json - ç»Ÿè®¡ä¿¡æ¯")
    
    def run(self):
        """è¿è¡Œä¸»æµç¨‹"""
        print("=" * 60)
        print("ğŸš€ å¢å¼ºç‰ˆå¹¿å‘Šè¿‡æ»¤è§„åˆ™ç”Ÿæˆå™¨")
        print("=" * 60)
        
        start_time = time.time()
        
        try:
            # 1. åŠ è½½å¹¶å¤„ç†è§„åˆ™æº
            self.load_and_process_sources()
            
            # 2. å¼ºåŒ–å¹¿å‘ŠåŸŸåæ‹¦æˆª
            self.enhance_ad_domains()
            
            # 3. åº”ç”¨æ™ºèƒ½ç™½åå•
            self.apply_intelligent_whitelist()
            
            # 4. ç”Ÿæˆä¼˜åŒ–çš„è§„åˆ™æ–‡ä»¶
            self.generate_optimized_files()
            
            # 5. è¿è¡Œæµ‹è¯•
            self.run_tests()
            
            # ç»Ÿè®¡ä¿¡æ¯
            end_time = time.time()
            elapsed = end_time - start_time
            
            print("\n" + "=" * 60)
            print("ğŸ‰ è§„åˆ™ç”Ÿæˆå®Œæˆï¼")
            print(f"â±ï¸  è€—æ—¶: {elapsed:.1f}ç§’")
            print(f"ğŸ“Š é»‘åå•åŸŸå: {len(self.black_domains):,}ä¸ª")
            print(f"ğŸ“Š ç™½åå•åŸŸå: {len(self.white_domains):,}ä¸ª")
            print("ğŸ“ è§„åˆ™æ–‡ä»¶: rules/outputs/")
            print("=" * 60)
            
            return True
            
        except Exception as e:
            print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def run_tests(self):
        """è¿è¡Œå¿«é€Ÿæµ‹è¯•"""
        print("ğŸ”¬ è¿è¡Œå¿«é€Ÿæµ‹è¯•...")
        
        # æ£€æŸ¥å¸¸è§å¹¿å‘ŠåŸŸåæ˜¯å¦è¢«åŒ…å«
        test_domains = CONFIG['STRONG_AD_DOMAINS']
        missing = []
        
        for domain in test_domains:
            if domain not in self.black_domains:
                missing.append(domain)
        
        if missing:
            print(f"âš ï¸  è­¦å‘Š: ä»¥ä¸‹å¼ºåŒ–å¹¿å‘ŠåŸŸåç¼ºå¤±:")
            for domain in missing[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"   - {domain}")
            print(f"  æ€»è®¡ç¼ºå¤±: {len(missing)} ä¸ª")
        else:
            print("âœ… æ‰€æœ‰å¼ºåŒ–å¹¿å‘ŠåŸŸåå‡å·²åŒ…å«")

def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥ä¾èµ–
    try:
        import requests
    except ImportError:
        print("âŒ ç¼ºå°‘ä¾èµ–ï¼šrequests")
        print("è¯·è¿è¡Œï¼špip install requests")
        return
    
    # è¿è¡Œç”Ÿæˆå™¨
    generator = EnhancedAdBlockGenerator()
    success = generator.run()
    
    if success:
        print("\nâœ¨ è§„åˆ™ç”ŸæˆæˆåŠŸï¼")
        print("ğŸ”¬ å»ºè®®è¿è¡Œæµ‹è¯•è„šæœ¬: python test_rules.py")
        print("ğŸ”„ å°†åœ¨ GitHub Actions è‡ªåŠ¨æ›´æ–°")
    else:
        print("\nğŸ’¥ è§„åˆ™ç”Ÿæˆå¤±è´¥ï¼")

if __name__ == "__main__":
    main()
