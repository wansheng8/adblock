#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¹¿å‘Šè¿‡æ»¤è§„åˆ™é›†åˆå™¨ - ä¸»ç¨‹åº
è‡ªåŠ¨æ”¶é›†ã€åˆå¹¶ã€å»é‡å¹¿å‘Šè¿‡æ»¤è§„åˆ™
"""

import os
import re
import json
import time
import requests
from datetime import datetime
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed

# è®¾ç½®æ—¶åŒºä¸ºä¸Šæµ·æ—¶é—´
os.environ['TZ'] = 'Asia/Shanghai'
try:
    time.tzset()
except:
    pass  # Windowsç³»ç»Ÿå¿½ç•¥

class AdblockRuleAggregator:
    def __init__(self):
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        self.sources_dir = os.path.join(self.base_dir, 'rules', 'sources')
        self.outputs_dir = os.path.join(self.base_dir, 'rules', 'outputs')
        
        # è§„åˆ™åˆ†ç±»æ­£åˆ™è¡¨è¾¾å¼
        self.rule_patterns = {
            'adblock': [
                r'^!.*',  # æ³¨é‡Š
                r'^\|\|.*\^',  # åŸŸåè§„åˆ™
                r'^@@\|\|.*\^',  # ç™½åå•
                r'^/.*/',  # æ­£åˆ™è¡¨è¾¾å¼
                r'^##.*',  # å…ƒç´ éšè—
                r'^#@#.*',  # å…ƒç´ éšè—ç™½åå•
                r'^\|\|.*\$.*',  # å¸¦é€‰é¡¹çš„è§„åˆ™
            ],
            'dns': [
                r'^0\.0\.0\.0\s+',
                r'^127\.0\.0\.1\s+',
                r'^::1\s+',
                r'^address=/.*/0\.0\.0\.0$',
                r'^server=/.*/0\.0\.0\.0$',
                r'^[a-zA-Z0-9.-]+\s+IN\s+A\s+0\.0\.0\.0',
            ],
            'hosts': [
                r'^\s*0\.0\.0\.0\s+[a-zA-Z0-9.-]+',
                r'^\s*127\.0\.0\.1\s+[a-zA-Z0-9.-]+',
                r'^\s*::1\s+[a-zA-Z0-9.-]+',
            ]
        }
        
        # å¹¿å‘Šè¿‡æ»¤åˆ†ç±»
        self.ad_categories = {
            'banner': [
                r'banner', r'å¹¿å‘Š', r'ad', r'ads', r'advert',
                r'gg', r'guanggao', r'æ¨å¹¿', r'sponsor'
            ],
            'popup': [
                r'popup', r'pop-up', r'å¼¹çª—', r'modal',
                r'overlay', r'lightbox', r'å¼¹å‡º'
            ],
            'tracker': [
                r'track', r'analytic', r'stat', r'ç›‘æµ‹',
                r'beacon', r'pixel', r'log', r'collect'
            ],
            'malware': [
                r'malware', r'virus', r'æ¶æ„', r'æ¬ºè¯ˆ',
                r'phishing', r'é’“é±¼', r'exploit'
            ],
            'social': [
                r'share', r'like', r'comment', r'ç¤¾äº¤',
                r'facebook', r'twitter', r'weibo'
            ]
        }
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
    def fetch_url(self, url):
        """è·å–URLå†…å®¹"""
        try:
            response = requests.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()
            
            # æ£€æµ‹ç¼–ç 
            if response.encoding is None or response.encoding == 'ISO-8859-1':
                response.encoding = 'utf-8'
                
            return response.text
        except Exception as e:
            print(f"âŒ è·å– {url} å¤±è´¥: {e}")
            return None
    
    def load_sources(self, filename):
        """åŠ è½½è§„åˆ™æº"""
        sources_file = os.path.join(self.sources_dir, filename)
        sources = []
        
        if os.path.exists(sources_file):
            with open(sources_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        sources.append(line)
        
        return sources
    
    def parse_rules(self, content, source_url):
        """è§£æè§„åˆ™å†…å®¹"""
        rules = {
            'adblock': [],
            'dns': [],
            'hosts': [],
            'black': [],
            'white': []
        }
        
        if not content:
            return rules
            
        lines = content.split('\n')
        domain = urlparse(source_url).netloc if source_url else 'unknown'
        
        for line in lines:
            line = line.strip()
            
            if not line or line.startswith('!'):
                continue
                
            # åˆ¤æ–­è§„åˆ™ç±»å‹
            rule_added = False
            
            # Adblockè§„åˆ™
            for pattern in self.rule_patterns['adblock']:
                if re.match(pattern, line):
                    rules['adblock'].append(line)
                    rule_added = True
                    break
            
            if not rule_added:
                # DNSè§„åˆ™
                for pattern in self.rule_patterns['dns']:
                    if re.match(pattern, line):
                        rules['dns'].append(line)
                        rule_added = True
                        break
            
            if not rule_added:
                # Hostsè§„åˆ™
                for pattern in self.rule_patterns['hosts']:
                    if re.match(pattern, line):
                        rules['hosts'].append(line)
                        rule_added = True
                        break
            
            # åˆ†ç±»ä¸ºé»‘åå•æˆ–ç™½åå•
            if line.startswith('@@'):
                if line not in rules['white']:
                    rules['white'].append(line)
            else:
                if line and line not in rules['black']:
                    rules['black'].append(line)
        
        return rules
    
    def deduplicate_rules(self, rules_dict):
        """å»é‡è§„åˆ™"""
        deduplicated = {}
        for rule_type, rules in rules_dict.items():
            # å»é‡å¹¶ä¿æŒé¡ºåº
            seen = set()
            deduplicated[rule_type] = []
            for rule in rules:
                if rule not in seen:
                    seen.add(rule)
                    deduplicated[rule_type].append(rule)
        return deduplicated
    
    def categorize_ad_rules(self, rules):
        """åˆ†ç±»å¹¿å‘Šè§„åˆ™"""
        categorized = {cat: [] for cat in self.ad_categories.keys()}
        categorized['other'] = []
        
        for rule in rules:
            rule_lower = rule.lower()
            matched = False
            
            for category, keywords in self.ad_categories.items():
                for keyword in keywords:
                    if re.search(keyword, rule_lower, re.IGNORECASE):
                        categorized[category].append(rule)
                        matched = True
                        break
                if matched:
                    break
            
            if not matched:
                categorized['other'].append(rule)
        
        return categorized
    
    def save_rules(self, rules_dict):
        """ä¿å­˜è§„åˆ™åˆ°æ–‡ä»¶"""
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.outputs_dir, exist_ok=True)
        
        # ä¿å­˜å„ç±»å‹è§„åˆ™
        for rule_type, rules in rules_dict.items():
            if rule_type in ['adblock', 'dns', 'hosts', 'black', 'white']:
                filename = os.path.join(self.outputs_dir, f"{rule_type}.txt")
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(f"! Title: AdBlock {rule_type.upper()} Rules\n")
                    f.write(f"! Updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"! Total rules: {len(rules)}\n")
                    f.write("! Project: https://github.com/wansheng8/adblock\n")
                    f.write("!\n")
                    
                    if rule_type == 'adblock':
                        f.write("! å…ƒç´ éšè—è§„åˆ™\n! æ¨ªå¹…å¹¿å‘Šæ‹¦æˆª\n! å¼¹çª—å¹¿å‘Šæ‹¦æˆª\n! åˆ†æå·¥å…·æ‹¦æˆª\n! é”™è¯¯æ‹¦æˆª\n")
                    
                    for rule in rules:
                        f.write(f"{rule}\n")
                
                print(f"âœ… ä¿å­˜ {rule_type}.txt: {len(rules)} æ¡è§„åˆ™")
        
        # ä¿å­˜åˆ†ç±»ç»Ÿè®¡ä¿¡æ¯
        ad_rules = rules_dict.get('adblock', [])
        categorized = self.categorize_ad_rules(ad_rules)
        
        info = {
            'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_rules': {
                'adblock': len(rules_dict.get('adblock', [])),
                'dns': len(rules_dict.get('dns', [])),
                'hosts': len(rules_dict.get('hosts', [])),
                'black': len(rules_dict.get('black', [])),
                'white': len(rules_dict.get('white', []))
            },
            'ad_categories': {
                category: len(rules) 
                for category, rules in categorized.items()
            },
            'source_count': {
                'black_sources': len(self.load_sources('black.txt')),
                'white_sources': len(self.load_sources('white.txt'))
            }
        }
        
        info_file = os.path.join(self.outputs_dir, 'info.json')
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ä¿å­˜ info.json: {json.dumps(info, ensure_ascii=False)}")
        
        return info
    
    def generate_readme(self, info):
        """ç”ŸæˆREADME.mdæ–‡ä»¶"""
        readme_path = os.path.join(self.base_dir, 'README.md')
        
        # åŠ è½½æºæ–‡ä»¶
        black_sources = self.load_sources('black.txt')
        white_sources = self.load_sources('white.txt')
        
        # ç”Ÿæˆè®¢é˜…é“¾æ¥è¡¨æ ¼
        subscription_table = "## ğŸ“¥ è®¢é˜…é“¾æ¥\n\n"
        subscription_table += "| è§„åˆ™ç±»å‹ | æ–‡ä»¶ | è®¢é˜…é“¾æ¥ | è§„åˆ™æ•°é‡ |\n"
        subscription_table += "|----------|------|----------|----------|\n"
        
        raw_base = "https://raw.githubusercontent.com/wansheng8/adblock/main/rules/outputs"
        
        files = [
            ("Adblock è§„åˆ™", "ad.txt", "å¹¿å‘Šæ‹¦æˆªã€å…ƒç´ éšè—"),
            ("DNS è§„åˆ™", "dns.txt", "DNSå±‚é¢æ‹¦æˆª"),
            ("Hosts è§„åˆ™", "hosts.txt", "ç³»ç»Ÿhostsæ–‡ä»¶"),
            ("é»‘åå•è§„åˆ™", "black.txt", "å®Œæ•´é»‘åå•"),
            ("ç™½åå•è§„åˆ™", "white.txt", "ä¾‹å¤–è§„åˆ™")
        ]
        
        for name, filename, desc in files:
            count = info['total_rules'].get(filename.replace('.txt', ''), 0)
            url = f"{raw_base}/{filename}"
            subscription_table += f"| {name} | `{filename}` | [è®¢é˜…é“¾æ¥]({url}) | {count} æ¡ |\n"
        
        # ç”ŸæˆREADMEå†…å®¹
        readme_content = f"""# ğŸ›¡ï¸ ç²¾å‡†è¶…çº§æ™ºèƒ½å¹¿å‘Šè¿‡æ»¤è§„åˆ™é›†åˆå™¨

ä¸€ä¸ªé«˜æ•ˆçš„å¹¿å‘Šè¿‡æ»¤è§„åˆ™é›†åˆå™¨ï¼Œè‡ªåŠ¨æ”¶é›†ã€åˆå¹¶ã€å»é‡æ¥è‡ªå¤šä¸ªæºçš„å¹¿å‘Šè¿‡æ»¤è§„åˆ™ï¼Œæä¾›å…¨é¢çš„å¹¿å‘Šæ‹¦æˆªè§£å†³æ–¹æ¡ˆã€‚

## âœ¨ ç‰¹æ€§

- ğŸ”„ **è‡ªåŠ¨æ›´æ–°**ï¼šæ¯å¤©è‡ªåŠ¨æ›´æ–°è§„åˆ™
- ğŸ§¹ **æ™ºèƒ½å»é‡**ï¼šè‡ªåŠ¨å»é™¤é‡å¤è§„åˆ™
- ğŸ·ï¸ **è§„åˆ™åˆ†ç±»**ï¼šæŒ‰ç±»å‹ï¼ˆAdblockã€DNSã€Hostsï¼‰åˆ†ç±»
- âš¡ **é«˜æ€§èƒ½**ï¼šå¹¶å‘ä¸‹è½½ï¼Œå¿«é€Ÿå¤„ç†
- ğŸ“Š **è¯¦ç»†ç»Ÿè®¡**ï¼šè§„åˆ™æ•°é‡ã€åˆ†ç±»ç»Ÿè®¡
- ğŸŒ **å¤šæºæ”¯æŒ**ï¼šæ”¯æŒå¤šä¸ªè§„åˆ™æº

{subscription_table}

## ğŸ“Š è§„åˆ™ç»Ÿè®¡

| åˆ†ç±» | æ•°é‡ | è¯´æ˜ |
|------|------|------|
| å¹¿å‘Šæ‹¦æˆªè§„åˆ™ | {info['total_rules']['adblock']} | å…ƒç´ éšè—ã€URLæ‹¦æˆª |
| DNS æ‹¦æˆªè§„åˆ™ | {info['total_rules']['dns']} | DNSå±‚é¢å¹¿å‘Šæ‹¦æˆª |
| Hosts è§„åˆ™ | {info['total_rules']['hosts']} | ç³»ç»Ÿhostsæ–‡ä»¶ |
| é»‘åå•æ€»æ•° | {info['total_rules']['black']} | æ€»æ‹¦æˆªè§„åˆ™ |
| ç™½åå•ä¾‹å¤– | {info['total_rules']['white']} | ä¸æ‹¦æˆªè§„åˆ™ |

## ğŸ¯ å¹¿å‘Šæ‹¦æˆªç±»å‹

| æ‹¦æˆªç±»å‹ | è§„åˆ™æ•°é‡ | è¯´æ˜ |
|----------|----------|------|
| æ¨ªå¹…å¹¿å‘Š | {info['ad_categories']['banner']} | é¡µé¢æ¨ªå¹…ã€ä¾§è¾¹æ å¹¿å‘Š |
| å¼¹çª—å¹¿å‘Š | {info['ad_categories']['popup']} | å¼¹çª—ã€æµ®å±‚å¹¿å‘Š |
| è·Ÿè¸ªåˆ†æ | {info['ad_categories']['tracker']} | ç»Ÿè®¡ã€åˆ†æå·¥å…· |
| æ¶æ„ç½‘ç«™ | {info['ad_categories']['malware']} | æ¶æ„è½¯ä»¶ã€é’“é±¼ç½‘ç«™ |
| ç¤¾äº¤æ’ä»¶ | {info['ad_categories']['social']} | ç¤¾äº¤åˆ†äº«æŒ‰é’® |
| å…¶ä»–è§„åˆ™ | {info['ad_categories']['other']} | æœªåˆ†ç±»è§„åˆ™ |

## ğŸ”„ æ›´æ–°ä¿¡æ¯

**æœ€æ–°æ›´æ–°æ—¶é—´ï¼š** {info['update_time']} (ä¸Šæµ·æ—¶é—´)

è§„åˆ™æºï¼š{info['source_count']['black_sources']} ä¸ªé»‘åå•æº + {info['source_count']['white_sources']} ä¸ªç™½åå•æº

---
**é¡¹ç›®åœ°å€ï¼š** [https://github.com/wansheng8/adblock](https://github.com/wansheng8/adblock)

*âš ï¸ æ³¨æ„ï¼šä½¿ç”¨å‰è¯·æµ‹è¯•è§„åˆ™å…¼å®¹æ€§ï¼Œéƒ¨åˆ†è§„åˆ™å¯èƒ½å½±å“ç½‘ç«™æ­£å¸¸åŠŸèƒ½*
"""
        
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        print(f"âœ… ç”Ÿæˆ README.md å®Œæˆ")
    
    def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        print("ğŸš€ å¼€å§‹æ”¶é›†å¹¿å‘Šè¿‡æ»¤è§„åˆ™...")
        print(f"ğŸ“ å·¥ä½œç›®å½•: {self.base_dir}")
        
        # åŠ è½½æº
        black_sources = self.load_sources('black.txt')
        white_sources = self.load_sources('white.txt')
        
        print(f"ğŸ“¥ æ‰¾åˆ° {len(black_sources)} ä¸ªé»‘åå•æº")
        print(f"ğŸ“¤ æ‰¾åˆ° {len(white_sources)} ä¸ªç™½åå•æº")
        
        all_rules = {
            'adblock': [],
            'dns': [],
            'hosts': [],
            'black': [],
            'white': []
        }
        
        # å¹¶å‘è·å–è§„åˆ™
        with ThreadPoolExecutor(max_workers=10) as executor:
            # è·å–é»‘åå•è§„åˆ™
            future_to_url = {}
            for url in black_sources:
                future = executor.submit(self.fetch_url, url)
                future_to_url[future] = ('black', url)
            
            for url in white_sources:
                future = executor.submit(self.fetch_url, url)
                future_to_url[future] = ('white', url)
            
            # å¤„ç†ç»“æœ
            for future in as_completed(future_to_url):
                source_type, url = future_to_url[future]
                content = future.result()
                
                if content:
                    print(f"âœ… è·å–æˆåŠŸ: {url}")
                    rules = self.parse_rules(content, url)
                    
                    # åˆå¹¶è§„åˆ™
                    for rule_type in all_rules.keys():
                        all_rules[rule_type].extend(rules[rule_type])
                else:
                    print(f"âŒ è·å–å¤±è´¥: {url}")
        
        # å»é‡
        print("ğŸ§¹ å»é‡å¤„ç†ä¸­...")
        deduplicated_rules = self.deduplicate_rules(all_rules)
        
        # ä¿å­˜è§„åˆ™
        print("ğŸ’¾ ä¿å­˜è§„åˆ™æ–‡ä»¶ä¸­...")
        info = self.save_rules(deduplicated_rules)
        
        # ç”ŸæˆREADME
        print("ğŸ“ ç”ŸæˆREADMEæ–‡æ¡£...")
        self.generate_readme(info)
        
        print(f"ğŸ‰ ä»»åŠ¡å®Œæˆï¼æ€»è®¡å¤„ç† {sum(len(r) for r in deduplicated_rules.values())} æ¡è§„åˆ™")
        print(f"ğŸ• æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

def main():
    """ä¸»å‡½æ•°"""
    aggregator = AdblockRuleAggregator()
    aggregator.run()

if __name__ == '__main__':
    main()
