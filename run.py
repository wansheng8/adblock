#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¹¿å‘Šè¿‡æ»¤è§„åˆ™ç”Ÿæˆå™¨ v3.0
æ™ºèƒ½ã€é«˜æ•ˆã€å¯é…ç½®çš„å¹¿å‘Šè¿‡æ»¤è§£å†³æ–¹æ¡ˆ
æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼å’Œå¢å¼ºæ‹¦æˆªåŠŸèƒ½
"""

import os
import re
import json
import yaml
import time
import logging
import argparse
import hashlib
import sqlite3
import threading
from datetime import datetime, timedelta
from typing import Set, List, Optional, Tuple, Dict, Any, Generator
from collections import defaultdict, Counter
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from urllib.parse import urlparse, urljoin
import dns.resolver
import psutil
import tldextract

# é…ç½®ç®¡ç†å™¨
class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = "config.yaml"):
        self.config_path = config_path
        self.config = self.load_config()
        self.validate_config()
    
    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # è®¾ç½®é»˜è®¤å€¼
            defaults = {
                'project': {
                    'version': '3.0.0',
                    'name': 'adblock-enhanced'
                },
                'performance': {
                    'max_workers': 10,
                    'timeout': 30
                }
            }
            
            # åˆå¹¶é…ç½®
            self._merge_dict(config, defaults)
            return config
            
        except Exception as e:
            logging.error(f"åŠ è½½é…ç½®å¤±è´¥: {e}")
            raise
    
    def _merge_dict(self, target: Dict, source: Dict) -> None:
        """é€’å½’åˆå¹¶å­—å…¸"""
        for key, value in source.items():
            if key in target and isinstance(target[key], dict) and isinstance(value, dict):
                self._merge_dict(target[key], value)
            elif key not in target:
                target[key] = value
    
    def validate_config(self) -> None:
        """éªŒè¯é…ç½®"""
        required_sections = ['github', 'performance', 'rules', 'paths']
        for section in required_sections:
            if section not in self.config:
                raise ValueError(f"ç¼ºå°‘å¿…è¦é…ç½®é¡¹: {section}")
    
    def get(self, key: str, default: Any = None) -> Any:
        """è·å–é…ç½®å€¼"""
        keys = key.split('.')
        value = self.config
        for k in keys:
            if isinstance(value, dict):
                value = value.get(k, default)
            else:
                return default
        return value if value is not None else default
    
    def save(self) -> None:
        """ä¿å­˜é…ç½®"""
        with open(self.config_path, 'w', encoding='utf-8') as f:
            yaml.dump(self.config, f, default_flow_style=False, allow_unicode=True)


# åŸŸåéªŒè¯å™¨
class DomainValidator:
    """åŸŸåéªŒè¯å™¨"""
    
    def __init__(self, config: ConfigManager):
        self.config = config
        self.tld_extractor = tldextract.TLDExtract(cache_dir="/tmp/tld_cache")
        
        # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        self.domain_pattern = re.compile(
            r'^(?!-)[A-Za-z0-9-]{1,63}(?<!-)(\.[A-Za-z0-9-]{1,63})*(\.[A-Za-z]{2,})$'
        )
        
        # ä¿ç•™å­—
        self.reserved_words = {
            'localhost', 'local', 'broadcasthost', 'localhost.localdomain',
            'ip6-localhost', 'ip6-loopback', 'ip6-localnet', 'ip6-mcastprefix'
        }
    
    def validate_domain(self, domain: str) -> Tuple[bool, str]:
        """
        éªŒè¯åŸŸåæœ‰æ•ˆæ€§
        
        Args:
            domain: åŸŸå
            
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        domain = domain.strip().lower()
        
        # åŸºæœ¬é•¿åº¦æ£€æŸ¥
        min_len = self.config.get('rules.validation.min_domain_length', 3)
        max_len = self.config.get('rules.validation.max_domain_length', 253)
        
        if len(domain) < min_len:
            return False, f"åŸŸåå¤ªçŸ­ (min: {min_len})"
        if len(domain) > max_len:
            return False, f"åŸŸåå¤ªé•¿ (max: {max_len})"
        
        # æ£€æŸ¥ä¿ç•™å­—
        if domain in self.reserved_words:
            return False, "ä¿ç•™å­—åŸŸå"
        
        # æ£€æŸ¥æ’é™¤åˆ—è¡¨
        exclude_list = self.config.get('rules.exclude_domains', [])
        if domain in exclude_list:
            return False, "åœ¨æ’é™¤åˆ—è¡¨ä¸­"
        
        # æ­£åˆ™è¡¨è¾¾å¼éªŒè¯
        if not self.domain_pattern.match(domain):
            return False, "æ ¼å¼æ— æ•ˆ"
        
        # æå–TLD
        try:
            extracted = self.tld_extractor(domain)
            if not extracted.suffix:
                return False, "ç¼ºå°‘é¡¶çº§åŸŸå"
            
            # æ£€æŸ¥TLDé•¿åº¦
            min_tld_len = self.config.get('rules.validation.min_tld_length', 2)
            if len(extracted.suffix) < min_tld_len:
                return False, f"TLDå¤ªçŸ­ (min: {min_tld_len})"
            
            # éªŒè¯TLDï¼ˆå¯é€‰ï¼‰
            if self.config.get('rules.validation.validate_tld', False):
                if not self._validate_tld(extracted.suffix):
                    return False, "æ— æ•ˆçš„TLD"
            
        except Exception as e:
            return False, f"TLDæå–å¤±è´¥: {e}"
        
        # æ£€æŸ¥å…è®¸çš„ç‰¹æ®Šå­—ç¬¦
        if not self.config.get('rules.validation.allow_underscores', False):
            if '_' in domain:
                return False, "åŒ…å«ä¸‹åˆ’çº¿"
        
        if not self.config.get('rules.validation.allow_hyphens', True):
            if '-' in domain:
                return False, "åŒ…å«è¿å­—ç¬¦"
        
        if not self.config.get('rules.validation.allow_numbers', True):
            if any(c.isdigit() for c in domain):
                return False, "åŒ…å«æ•°å­—"
        
        # æ£€æŸ¥è¿ç»­ç‰¹æ®Šå­—ç¬¦
        if '..' in domain or '--' in domain:
            return False, "è¿ç»­ç‰¹æ®Šå­—ç¬¦"
        
        # æ£€æŸ¥å¼€å¤´å’Œç»“å°¾
        if domain.startswith('-') or domain.startswith('.'):
            return False, "ä»¥ç‰¹æ®Šå­—ç¬¦å¼€å¤´"
        if domain.endswith('-') or domain.endswith('.'):
            return False, "ä»¥ç‰¹æ®Šå­—ç¬¦ç»“å°¾"
        
        return True, "æœ‰æ•ˆ"
    
    def _validate_tld(self, tld: str) -> bool:
        """éªŒè¯é¡¶çº§åŸŸå"""
        # è¿™é‡Œå¯ä»¥é›†æˆå…¬å…±åç¼€åˆ—è¡¨
        # æš‚æ—¶ä½¿ç”¨ç®€å•çš„æ£€æŸ¥
        return len(tld) >= 2 and '.' in tld
    
    def normalize_domain(self, domain: str) -> str:
        """æ ‡å‡†åŒ–åŸŸå"""
        domain = domain.strip().lower()
        
        # ç§»é™¤åè®®å’Œè·¯å¾„
        if '://' in domain:
            domain = urlparse(domain).netloc
        
        # ç§»é™¤ç«¯å£
        if ':' in domain:
            domain = domain.split(':')[0]
        
        # ç§»é™¤wwwå‰ç¼€
        if domain.startswith('www.'):
            domain = domain[4:]
        
        # ç§»é™¤æœ«å°¾çš„ç‚¹
        domain = domain.rstrip('.')
        
        return domain


# è§„åˆ™å¤„ç†å™¨
class RuleProcessor:
    """è§„åˆ™å¤„ç†å™¨"""
    
    def __init__(self, config: ConfigManager, validator: DomainValidator):
        self.config = config
        self.validator = validator
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_processed': 0,
            'valid_domains': 0,
            'invalid_domains': 0,
            'removed_by_whitelist': 0,
            'removed_by_safe_check': 0,
            'removed_by_suspicious': 0,
            'added_by_enhancement': 0,
            'element_hiding_rules': 0,
            'script_blocking_rules': 0
        }
        
        # ç¼“å­˜
        self.black_domains = set()
        self.white_domains = set()
        self.enhanced_domains = set()
        self.element_hiding_rules = set()
        self.script_blocking_rules = set()
        
        # åŠ è½½å†…ç½®è§„åˆ™
        self._load_builtin_rules()
    
    def _load_builtin_rules(self) -> None:
        """åŠ è½½å†…ç½®è§„åˆ™"""
        # ä»é…ç½®åŠ è½½è§„åˆ™
        config_dir = os.path.join(
            self.config.get('paths.base_dir', '.'),
            self.config.get('paths.custom_sources', 'rules/sources/custom')
        )
        
        if os.path.exists(config_dir):
            for file in os.listdir(config_dir):
                if file.endswith(('.txt', '.json')):
                    self._load_custom_rules(os.path.join(config_dir, file))
    
    def _load_custom_rules(self, file_path: str) -> None:
        """åŠ è½½è‡ªå®šä¹‰è§„åˆ™"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
                # æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†
                if file_path.endswith('.json'):
                    rules = json.loads(content)
                    # å¤„ç†JSONæ ¼å¼è§„åˆ™
                else:
                    # å¤„ç†æ–‡æœ¬æ ¼å¼è§„åˆ™
                    lines = content.split('\n')
                    for line in lines:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            self._process_rule_line(line)
        except Exception as e:
            logging.warning(f"åŠ è½½è‡ªå®šä¹‰è§„åˆ™å¤±è´¥ {file_path}: {e}")
    
    def _process_rule_line(self, line: str) -> None:
        """å¤„ç†å•è¡Œè§„åˆ™"""
        # è¿™é‡Œå®ç°è§„åˆ™è§£æé€»è¾‘
        pass
    
    def process_source(self, content: str, source_type: str = 'black') -> Set[str]:
        """å¤„ç†è§„åˆ™æºå†…å®¹"""
        domains = set()
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith(('#', '!', '//')):
                continue
            
            extracted = self._extract_domain_from_rule(line)
            if extracted:
                domain, is_whitelist = extracted
                
                # éªŒè¯åŸŸå
                is_valid, _ = self.validator.validate_domain(domain)
                if is_valid:
                    if is_whitelist:
                        self.white_domains.add(domain)
                    else:
                        domains.add(domain)
                    self.stats['valid_domains'] += 1
                else:
                    self.stats['invalid_domains'] += 1
        
        return domains
    
    def _extract_domain_from_rule(self, rule: str) -> Optional[Tuple[str, bool]]:
        """ä»è§„åˆ™ä¸­æå–åŸŸå"""
        rule = rule.strip()
        is_whitelist = rule.startswith('@@')
        
        if is_whitelist:
            rule = rule[2:]
        
        # å¤„ç†å¸¸è§è§„åˆ™æ ¼å¼
        patterns = [
            (r'^\|\|([^\^]+)\^\$?.*$', 1),  # ||domain.com^
            (r'^([^\^]+)\^\$?.*$', 1),      # domain.com^
            (r'^0\.0\.0\.0\s+([^\s]+)$', 1),  # 0.0.0.0 domain.com
            (r'^127\.0\.0\.1\s+([^\s]+)$', 1),  # 127.0.0.1 domain.com
            (r'^([a-zA-Z0-9.-]+)$', 1),      # domain.com
        ]
        
        for pattern, group in patterns:
            match = re.match(pattern, rule)
            if match:
                domain = match.group(group)
                normalized = self.validator.normalize_domain(domain)
                return normalized, is_whitelist
        
        return None
    
    def apply_intelligent_filtering(self, domains: Set[str]) -> Set[str]:
        """åº”ç”¨æ™ºèƒ½è¿‡æ»¤"""
        filtered_domains = set(domains)
        
        # 1. ç™½åå•è¿‡æ»¤
        filtered_domains = self._apply_whitelist(filtered_domains)
        
        # 2. å®‰å…¨åŸŸåæ£€æŸ¥
        if self.config.get('rules.intelligent_filtering.enable_safe_domains_check', True):
            filtered_domains = self._filter_safe_domains(filtered_domains)
        
        # 3. è¯¯æŠ¥è¿‡æ»¤
        if self.config.get('rules.intelligent_filtering.enable_false_positive_filter', True):
            filtered_domains = self._filter_false_positives(filtered_domains)
        
        # 4. åŸŸåéªŒè¯
        if self.config.get('rules.intelligent_filtering.enable_domain_validation', True):
            filtered_domains = self._validate_domains(filtered_domains)
        
        return filtered_domains
    
    def _apply_whitelist(self, domains: Set[str]) -> Set[str]:
        """åº”ç”¨ç™½åå•"""
        filtered = set()
        removed = 0
        
        for domain in domains:
            is_whitelisted = False
            
            # æ£€æŸ¥ç²¾ç¡®åŒ¹é…
            if domain in self.white_domains:
                is_whitelisted = True
            else:
                # æ£€æŸ¥å­åŸŸååŒ¹é…
                for white_domain in self.white_domains:
                    if domain.endswith(f".{white_domain}"):
                        is_whitelisted = True
                        break
            
            if not is_whitelisted:
                filtered.add(domain)
            else:
                removed += 1
        
        self.stats['removed_by_whitelist'] = removed
        return filtered
    
    def _filter_safe_domains(self, domains: Set[str]) -> Set[str]:
        """è¿‡æ»¤å®‰å…¨åŸŸå"""
        # å®ç°å®‰å…¨åŸŸåæ£€æŸ¥é€»è¾‘
        return domains
    
    def _filter_false_positives(self, domains: Set[str]) -> Set[str]:
        """è¿‡æ»¤è¯¯æŠ¥"""
        # å®ç°è¯¯æŠ¥è¿‡æ»¤é€»è¾‘
        return domains
    
    def _validate_domains(self, domains: Set[str]) -> Set[str]:
        """éªŒè¯åŸŸå"""
        filtered = set()
        removed = 0
        
        for domain in domains:
            is_valid, _ = self.validator.validate_domain(domain)
            if is_valid:
                filtered.add(domain)
            else:
                removed += 1
        
        return filtered
    
    def enhance_blocking(self, domains: Set[str]) -> Set[str]:
        """å¢å¼ºæ‹¦æˆª"""
        enhanced = set(domains)
        
        # åˆ†æå·¥å…·æ‹¦æˆª
        if self.config.get('rules.enhanced_blocking.analytics.enabled', True):
            enhanced = self._enhance_analytics_blocking(enhanced)
        
        # æ¨ªå¹…å¹¿å‘Šæ‹¦æˆª
        if self.config.get('rules.enhanced_blocking.banner_ads.enabled', True):
            enhanced = self._enhance_banner_blocking(enhanced)
        
        # å…ƒç´ éšè—è§„åˆ™
        if self.config.get('rules.enhanced_blocking.element_hiding.enabled', True):
            self._generate_element_hiding_rules()
        
        # è„šæœ¬æ‹¦æˆªè§„åˆ™
        if self.config.get('rules.enhanced_blocking.script_blocking.enabled', True):
            self._generate_script_blocking_rules()
        
        return enhanced
    
    def _enhance_analytics_blocking(self, domains: Set[str]) -> Set[str]:
        """å¢å¼ºåˆ†æå·¥å…·æ‹¦æˆª"""
        # å®ç°åˆ†æå·¥å…·æ‹¦æˆªå¢å¼º
        return domains
    
    def _enhance_banner_blocking(self, domains: Set[str]) -> Set[str]:
        """å¢å¼ºæ¨ªå¹…å¹¿å‘Šæ‹¦æˆª"""
        # å®ç°æ¨ªå¹…å¹¿å‘Šæ‹¦æˆªå¢å¼º
        return domains
    
    def _generate_element_hiding_rules(self) -> None:
        """ç”Ÿæˆå…ƒç´ éšè—è§„åˆ™"""
        # å®ç°å…ƒç´ éšè—è§„åˆ™ç”Ÿæˆ
        pass
    
    def _generate_script_blocking_rules(self) -> None:
        """ç”Ÿæˆè„šæœ¬æ‹¦æˆªè§„åˆ™"""
        # å®ç°è„šæœ¬æ‹¦æˆªè§„åˆ™ç”Ÿæˆ
        pass


# ç½‘ç»œç®¡ç†å™¨
class NetworkManager:
    """ç½‘ç»œç®¡ç†å™¨"""
    
    def __init__(self, config: ConfigManager):
        self.config = config
        self.session = self._create_session()
        self.cache = {}
        self.cache_lock = threading.Lock()
    
    def _create_session(self) -> requests.Session:
        """åˆ›å»ºè¯·æ±‚ä¼šè¯"""
        session = requests.Session()
        
        # é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=self.config.get('network.retry_times', 3),
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS"]
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        # è®¾ç½®è¯·æ±‚å¤´
        session.headers.update({
            'User-Agent': self.config.get('network.user_agent', 'AdBlockGenerator/3.0'),
            'Accept': 'text/plain,text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Encoding': self.config.get('network.accept_encoding', 'gzip, deflate'),
            'Accept-Language': 'en-US,en;q=0.9',
            'Connection': 'keep-alive'
        })
        
        return session
    
    def fetch_url(self, url: str, use_cache: bool = True) -> Optional[str]:
        """è·å–URLå†…å®¹"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = hashlib.md5(url.encode()).hexdigest()
        
        if use_cache:
            with self.cache_lock:
                if cache_key in self.cache:
                    content, timestamp = self.cache[cache_key]
                    cache_expiry = self.config.get('performance.cache_expiry_hours', 24)
                    if time.time() - timestamp < cache_expiry * 3600:
                        return content
        
        try:
            response = self.session.get(
                url,
                timeout=self.config.get('network.timeout', 30),
                verify=self.config.get('network.verify_ssl', True)
            )
            
            response.raise_for_status()
            content = response.text
            
            # æ›´æ–°ç¼“å­˜
            with self.cache_lock:
                self.cache[cache_key] = (content, time.time())
            
            return content
            
        except requests.RequestException as e:
            logging.error(f"è·å–URLå¤±è´¥ {url}: {e}")
            return None
    
    def fetch_multiple_urls(self, urls: List[str], max_workers: int = 10) -> Dict[str, Optional[str]]:
        """æ‰¹é‡è·å–URL"""
        results = {}
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_url = {
                executor.submit(self.fetch_url, url): url
                for url in urls
            }
            
            for future in as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    content = future.result()
                    results[url] = content
                except Exception as e:
                    logging.error(f"æ‰¹é‡è·å–å¤±è´¥ {url}: {e}")
                    results[url] = None
        
        return results


# æ–‡ä»¶ç®¡ç†å™¨
class FileManager:
    """æ–‡ä»¶ç®¡ç†å™¨"""
    
    def __init__(self, config: ConfigManager):
        self.config = config
        self._setup_directories()
    
    def _setup_directories(self) -> None:
        """è®¾ç½®ç›®å½•ç»“æ„"""
        directories = [
            self.config.get('paths.sources_dir'),
            self.config.get('paths.outputs_dir'),
            self.config.get('paths.cache_dir'),
            self.config.get('paths.logs_dir'),
            self.config.get('paths.reports_dir'),
            self.config.get('paths.backup_dir'),
        ]
        
        for directory in directories:
            if directory:
                os.makedirs(directory, exist_ok=True)
    
    def save_output(self, filename: str, content: str, compress: bool = False) -> bool:
        """ä¿å­˜è¾“å‡ºæ–‡ä»¶"""
        try:
            filepath = os.path.join(
                self.config.get('paths.outputs_dir'),
                filename
            )
            
            # åˆ›å»ºå¤‡ä»½
            if os.path.exists(filepath):
                self._create_backup(filepath)
            
            # å†™å…¥æ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            # å‹ç¼©ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if compress:
                self._compress_file(filepath)
            
            return True
            
        except Exception as e:
            logging.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ {filename}: {e}")
            return False
    
    def _create_backup(self, filepath: str) -> None:
        """åˆ›å»ºå¤‡ä»½"""
        backup_dir = self.config.get('paths.backup_dir')
        if not backup_dir:
            return
        
        filename = os.path.basename(filepath)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_path = os.path.join(backup_dir, f"{filename}.{timestamp}.bak")
        
        try:
            import shutil
            shutil.copy2(filepath, backup_path)
            
            # æ¸…ç†æ—§å¤‡ä»½
            self._cleanup_old_backups(filename)
            
        except Exception as e:
            logging.warning(f"åˆ›å»ºå¤‡ä»½å¤±è´¥ {filepath}: {e}")
    
    def _cleanup_old_backups(self, filename: str) -> None:
        """æ¸…ç†æ—§å¤‡ä»½"""
        backup_dir = self.config.get('paths.backup_dir')
        if not backup_dir:
            return
        
        max_backups = self.config.get('auto_update.max_backups', 5)
        pattern = f"{filename}.*.bak"
        
        backups = []
        for file in os.listdir(backup_dir):
            if re.match(pattern, file):
                filepath = os.path.join(backup_dir, file)
                backups.append((filepath, os.path.getmtime(filepath)))
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        backups.sort(key=lambda x: x[1], reverse=True)
        
        # åˆ é™¤å¤šä½™çš„å¤‡ä»½
        for filepath, _ in backups[max_backups:]:
            try:
                os.remove(filepath)
            except Exception as e:
                logging.warning(f"åˆ é™¤æ—§å¤‡ä»½å¤±è´¥ {filepath}: {e}")
    
    def _compress_file(self, filepath: str) -> None:
        """å‹ç¼©æ–‡ä»¶"""
        try:
            import gzip
            
            with open(filepath, 'rb') as f_in:
                with gzip.open(f"{filepath}.gz", 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
                    
        except Exception as e:
            logging.warning(f"å‹ç¼©æ–‡ä»¶å¤±è´¥ {filepath}: {e}")


# ç›‘æ§å™¨
class Monitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.start_time = time.time()
        self.memory_start = psutil.Process().memory_info().rss
        self.metrics = {
            'performance': {},
            'memory': {},
            'network': {},
            'files': {}
        }
    
    def start_monitoring(self) -> None:
        """å¼€å§‹ç›‘æ§"""
        self.start_time = time.time()
        self.memory_start = psutil.Process().memory_info().rss
    
    def stop_monitoring(self) -> Dict[str, Any]:
        """åœæ­¢ç›‘æ§å¹¶è¿”å›ç»“æœ"""
        end_time = time.time()
        memory_end = psutil.Process().memory_info().rss
        
        self.metrics['performance']['total_time'] = end_time - self.start_time
        self.metrics['memory']['used_mb'] = (memory_end - self.memory_start) / 1024 / 1024
        self.metrics['memory']['peak_mb'] = psutil.Process().memory_info().rss / 1024 / 1024
        
        # è·å–ç³»ç»Ÿä¿¡æ¯
        self.metrics['system'] = {
            'cpu_percent': psutil.cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_usage': psutil.disk_usage('/').percent
        }
        
        return self.metrics
    
    def record_metric(self, category: str, key: str, value: Any) -> None:
        """è®°å½•æŒ‡æ ‡"""
        if category not in self.metrics:
            self.metrics[category] = {}
        self.metrics[category][key] = value


# ä¸»ç”Ÿæˆå™¨
class AdBlockGenerator:
    """å¹¿å‘Šè¿‡æ»¤è§„åˆ™ç”Ÿæˆå™¨ä¸»ç±»"""
    
    def __init__(self, config_path: str = "config.yaml"):
        # åˆå§‹åŒ–ç»„ä»¶
        self.config = ConfigManager(config_path)
        self.validator = DomainValidator(self.config)
        self.processor = RuleProcessor(self.config, self.validator)
        self.network = NetworkManager(self.config)
        self.files = FileManager(self.config)
        self.monitor = Monitor()
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        # çŠ¶æ€
        self.black_domains = set()
        self.white_domains = set()
        self.enhanced_domains = set()
        
        # ç‰ˆæœ¬ä¿¡æ¯
        self.version = self.config.get('project.version', '3.0.0')
        self.build_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    def _setup_logging(self) -> None:
        """è®¾ç½®æ—¥å¿—"""
        log_level = self.config.get('monitoring.log_level', 'INFO').upper()
        log_file = self.config.get('paths.error_log', 'logs/error.log')
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        
        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            level=getattr(logging, log_level),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        
        self.logger = logging.getLogger(__name__)
    
    def run(self, mode: str = 'normal') -> bool:
        """
        è¿è¡Œè§„åˆ™ç”Ÿæˆå™¨
        
        Args:
            mode: è¿è¡Œæ¨¡å¼ (normal, strict, loose, enhanced)
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        self.logger.info(f"å¯åŠ¨å¹¿å‘Šè¿‡æ»¤è§„åˆ™ç”Ÿæˆå™¨ v{self.version}")
        self.monitor.start_monitoring()
        
        try:
            # 1. åŠ è½½æº
            self.logger.info("æ­¥éª¤ 1/5: åŠ è½½è§„åˆ™æº")
            if not self._load_sources():
                return False
            
            # 2. ä¸‹è½½å’Œå¤„ç†è§„åˆ™
            self.logger.info("æ­¥éª¤ 2/5: ä¸‹è½½å’Œå¤„ç†è§„åˆ™")
            if not self._process_sources():
                return False
            
            # 3. æ™ºèƒ½è¿‡æ»¤å’Œå¢å¼º
            self.logger.info("æ­¥éª¤ 3/5: æ™ºèƒ½è¿‡æ»¤å’Œå¢å¼º")
            self._apply_filters_and_enhancements(mode)
            
            # 4. ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
            self.logger.info("æ­¥éª¤ 4/5: ç”Ÿæˆè¾“å‡ºæ–‡ä»¶")
            if not self._generate_outputs():
                return False
            
            # 5. ç”ŸæˆæŠ¥å‘Šå’ŒREADME
            self.logger.info("æ­¥éª¤ 5/5: ç”ŸæˆæŠ¥å‘Šå’ŒREADME")
            self._generate_reports()
            self._generate_readme()
            
            # ç›‘æ§ç»“æœ
            metrics = self.monitor.stop_monitoring()
            self.logger.info(f"å¤„ç†å®Œæˆ! è€—æ—¶: {metrics['performance']['total_time']:.2f}ç§’")
            
            return True
            
        except Exception as e:
            self.logger.error(f"è¿è¡Œå¤±è´¥: {e}", exc_info=True)
            return False
    
    def _load_sources(self) -> bool:
        """åŠ è½½è§„åˆ™æº"""
        # åŠ è½½å†…ç½®æº
        black_sources = self.config.get('rules.sources.blacklist', [])
        white_sources = self.config.get('rules.sources.whitelist', [])
        
        # åŠ è½½æ–‡ä»¶æº
        black_file = self.config.get('paths.black_source')
        white_file = self.config.get('paths.white_source')
        
        if os.path.exists(black_file):
            try:
                with open(black_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    black_sources.extend([line.strip() for line in lines if line.strip() and not line.startswith('#')])
            except Exception as e:
                self.logger.warning(f"åŠ è½½é»‘åå•æ–‡ä»¶å¤±è´¥: {e}")
        
        if os.path.exists(white_file):
            try:
                with open(white_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    white_sources.extend([line.strip() for line in lines if line.strip() and not line.startswith('#')])
            except Exception as e:
                self.logger.warning(f"åŠ è½½ç™½åå•æ–‡ä»¶å¤±è´¥: {e}")
        
        # å»é‡
        self.black_sources = list(set(black_sources))
        self.white_sources = list(set(white_sources))
        
        self.logger.info(f"åŠ è½½äº† {len(self.black_sources)} ä¸ªé»‘åå•æºå’Œ {len(self.white_sources)} ä¸ªç™½åå•æº")
        return True
    
    def _process_sources(self) -> bool:
        """å¤„ç†è§„åˆ™æº"""
        # ä¸‹è½½æ‰€æœ‰æº
        all_urls = self.black_sources + self.white_sources
        results = self.network.fetch_multiple_urls(
            all_urls,
            max_workers=self.config.get('performance.max_workers', 10)
        )
        
        # å¤„ç†é»‘åå•
        black_domains = set()
        for url in self.black_sources:
            if url in results and results[url]:
                domains = self.processor.process_source(results[url], 'black')
                black_domains.update(domains)
        
        # å¤„ç†ç™½åå•
        white_domains = set()
        for url in self.white_sources:
            if url in results and results[url]:
                domains = self.processor.process_source(results[url], 'white')
                white_domains.update(domains)
        
        self.black_domains = black_domains
        self.white_domains = white_domains
        
        self.logger.info(f"å¤„ç†å®Œæˆ: {len(self.black_domains)} é»‘åå•åŸŸå, {len(self.white_domains)} ç™½åå•åŸŸå")
        return True
    
    def _apply_filters_and_enhancements(self, mode: str) -> None:
        """åº”ç”¨è¿‡æ»¤å’Œå¢å¼º"""
        # åº”ç”¨æ™ºèƒ½è¿‡æ»¤
        filtered_domains = self.processor.apply_intelligent_filtering(self.black_domains)
        
        # æ ¹æ®æ¨¡å¼è°ƒæ•´
        if mode == 'strict':
            # ä¸¥æ ¼æ¨¡å¼ï¼šæ›´å¤šè¿‡æ»¤
            pass
        elif mode == 'loose':
            # å®½æ¾æ¨¡å¼ï¼šå‡å°‘è¿‡æ»¤
            pass
        elif mode == 'enhanced':
            # å¢å¼ºæ¨¡å¼ï¼šæ›´å¤šæ‹¦æˆª
            filtered_domains = self.processor.enhance_blocking(filtered_domains)
        
        self.enhanced_domains = filtered_domains
        self.logger.info(f"è¿‡æ»¤åå‰©ä½™: {len(self.enhanced_domains)} ä¸ªåŸŸå")
    
    def _generate_outputs(self) -> bool:
        """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # 1. ç”ŸæˆAdblockè§„åˆ™
        ad_content = self._generate_adblock_rules(timestamp)
        if not self.files.save_output('ad.txt', ad_content):
            return False
        
        # 2. ç”ŸæˆDNSè§„åˆ™
        dns_content = self._generate_dns_rules(timestamp)
        if not self.files.save_output('dns.txt', dns_content):
            return False
        
        # 3. ç”ŸæˆHostsè§„åˆ™
        hosts_content = self._generate_hosts_rules(timestamp)
        if not self.files.save_output('hosts.txt', hosts_content):
            return False
        
        # 4. ç”Ÿæˆå¢å¼ºè§„åˆ™
        enhanced_content = self._generate_enhanced_rules(timestamp)
        if not self.files.save_output('enhanced.txt', enhanced_content):
            return False
        
        # 5. ç”Ÿæˆä¿¡æ¯æ–‡ä»¶
        info_content = self._generate_info_file(timestamp)
        if not self.files.save_output('info.json', info_content):
            return False
        
        return True
    
    def _generate_adblock_rules(self, timestamp: str) -> str:
        """ç”ŸæˆAdblockè§„åˆ™"""
        content = [
            f"! å¹¿å‘Šè¿‡æ»¤è§„åˆ™ v{self.version}",
            f"! ç”Ÿæˆæ—¶é—´: {timestamp}",
            f"! åŸŸåæ•°é‡: {len(self.enhanced_domains)}",
            f"! é¡¹ç›®åœ°å€: https://github.com/{self.config.get('github.user')}/{self.config.get('github.repo')}",
            "!",
            "! ========== ç™½åå•è§„åˆ™ =========="
        ]
        
        # æ·»åŠ ç™½åå•è§„åˆ™
        for domain in sorted(self.white_domains):
            content.append(f"@@||{domain}^")
        
        content.extend([
            "!",
            "! ========== å…ƒç´ éšè—è§„åˆ™ =========="
        ])
        
        # æ·»åŠ å…ƒç´ éšè—è§„åˆ™
        for rule in sorted(self.processor.element_hiding_rules):
            content.append(rule)
        
        content.extend([
            "!",
            "! ========== è„šæœ¬æ‹¦æˆªè§„åˆ™ =========="
        ])
        
        # æ·»åŠ è„šæœ¬æ‹¦æˆªè§„åˆ™
        for rule in sorted(self.processor.script_blocking_rules):
            content.append(rule)
        
        content.extend([
            "!",
            "! ========== é»‘åå•è§„åˆ™ =========="
        ])
        
        # æ·»åŠ é»‘åå•è§„åˆ™
        for domain in sorted(self.enhanced_domains):
            content.append(f"||{domain}^")
        
        return '\n'.join(content)
    
    def _generate_dns_rules(self, timestamp: str) -> str:
        """ç”ŸæˆDNSè§„åˆ™"""
        content = [
            f"# DNSè¿‡æ»¤è§„åˆ™ v{self.version}",
            f"# ç”Ÿæˆæ—¶é—´: {timestamp}",
            f"# åŸŸåæ•°é‡: {len(self.enhanced_domains)}",
            "#"
        ]
        
        for domain in sorted(self.enhanced_domains):
            content.append(domain)
        
        return '\n'.join(content)
    
    def _generate_hosts_rules(self, timestamp: str) -> str:
        """ç”ŸæˆHostsè§„åˆ™"""
        content = [
            f"# Hostsæ ¼å¼å¹¿å‘Šè¿‡æ»¤è§„åˆ™ v{self.version}",
            f"# ç”Ÿæˆæ—¶é—´: {timestamp}",
            f"# åŸŸåæ•°é‡: {len(self.enhanced_domains)}",
            "#",
            "127.0.0.1 localhost",
            "::1 localhost",
            "#"
        ]
        
        for domain in sorted(self.enhanced_domains):
            content.append(f"0.0.0.0 {domain}")
        
        return '\n'.join(content)
    
    def _generate_enhanced_rules(self, timestamp: str) -> str:
        """ç”Ÿæˆå¢å¼ºè§„åˆ™"""
        content = [
            f"! å¢å¼ºå¹¿å‘Šè¿‡æ»¤è§„åˆ™ v{self.version}",
            f"! ç”Ÿæˆæ—¶é—´: {timestamp}",
            f"! å¢å¼ºæ‹¦æˆªåŸŸå: {len(self.processor.enhanced_domains)}",
            "!",
            "! ========== åˆ†æå·¥å…·æ‹¦æˆª =========="
        ]
        
        # æ·»åŠ å¢å¼ºæ‹¦æˆªè§„åˆ™
        for domain in sorted(self.processor.enhanced_domains):
            content.append(f"||{domain}^$third-party")
        
        return '\n'.join(content)
    
    def _generate_info_file(self, timestamp: str) -> str:
        """ç”Ÿæˆä¿¡æ¯æ–‡ä»¶"""
        info = {
            'version': self.version,
            'build_date': self.build_date,
            'timestamp': timestamp,
            'stats': self.processor.stats,
            'metrics': self.monitor.metrics,
            'config': {
                'github': self.config.get('github'),
                'performance': self.config.get('performance'),
                'rules': {
                    'blacklist_count': len(self.black_domains),
                    'whitelist_count': len(self.white_domains),
                    'enhanced_count': len(self.enhanced_domains)
                }
            },
            'files': {
                'ad_txt': f"https://raw.githubusercontent.com/{self.config.get('github.user')}/{self.config.get('github.repo')}/{self.config.get('github.branch')}/rules/outputs/ad.txt",
                'dns_txt': f"https://raw.githubusercontent.com/{self.config.get('github.user')}/{self.config.get('github.repo')}/{self.config.get('github.branch')}/rules/outputs/dns.txt",
                'hosts_txt': f"https://raw.githubusercontent.com/{self.config.get('github.user')}/{self.config.get('github.repo')}/{self.config.get('github.branch')}/rules/outputs/hosts.txt"
            }
        }
        
        return json.dumps(info, indent=2, ensure_ascii=False)
    
    def _generate_reports(self) -> None:
        """ç”ŸæˆæŠ¥å‘Š"""
        # è¿™é‡Œå®ç°æŠ¥å‘Šç”Ÿæˆé€»è¾‘
        pass
    
    def _generate_readme(self) -> None:
        """ç”ŸæˆREADME.md"""
        base_url = f"https://raw.githubusercontent.com/{self.config.get('github.user')}/{self.config.get('github.repo')}/{self.config.get('github.branch')}"
        cdn_url = f"https://cdn.jsdelivr.net/gh/{self.config.get('github.user')}/{self.config.get('github.repo')}@{self.config.get('github.branch')}"
        
        readme_content = f"""# å¹¿å‘Šè¿‡æ»¤è§„åˆ™ v{self.version}

ä¸€ä¸ªç²¾å‡†çš„å¹¿å‘Šè¿‡æ»¤è§„åˆ™é›†åˆï¼Œè‡ªåŠ¨æ›´æ–°ç»´æŠ¤ï¼Œé€‚ç”¨äºå„ç§å¹¿å‘Šæ‹¦æˆªå™¨ã€DNSè¿‡æ»¤å™¨å’ŒHostsæ–‡ä»¶ã€‚

## è®¢é˜…åœ°å€

| è§„åˆ™åç§° | è§„åˆ™ç±»å‹ | åŸå§‹é“¾æ¥ | åŠ é€Ÿé“¾æ¥ |
|----------|----------|----------|----------|
| ç»¼åˆå¹¿å‘Šè¿‡æ»¤è§„åˆ™ | Adblock | `{base_url}/rules/outputs/ad.txt` | `{cdn_url}/rules/outputs/ad.txt` |
| DNSè¿‡æ»¤è§„åˆ™ | DNS | `{base_url}/rules/outputs/dns.txt` | `{cdn_url}/rules/outputs/dns.txt` |
| Hostsæ ¼å¼è§„åˆ™ | Hosts | `{base_url}/rules/outputs/hosts.txt` | `{cdn_url}/rules/outputs/hosts.txt` |
| å¢å¼ºè¿‡æ»¤è§„åˆ™ | Enhanced | `{base_url}/rules/outputs/enhanced.txt` | `{cdn_url}/rules/outputs/enhanced.txt` |
| éšç§ä¿æŠ¤è§„åˆ™ | Privacy | `{base_url}/rules/outputs/privacy.txt` | `{cdn_url}/rules/outputs/privacy.txt` |

## ç»Ÿè®¡æ•°æ®

- **é»‘åå•åŸŸå**: {len(self.black_domains):,}
- **ç™½åå•åŸŸå**: {len(self.white_domains):,}
- **å¢å¼ºæ‹¦æˆªåŸŸå**: {len(self.enhanced_domains):,}
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ›´æ–°é¢‘ç‡

è§„åˆ™æ¯å¤©è‡ªåŠ¨æ›´æ–°ï¼Œæ›´æ–°æ—¶é—´ï¼šåŒ—äº¬æ—¶é—´ 02:00

## è®¸å¯è¯

MIT License

Copyright (c) {datetime.now().year} {self.config.get('project.author')}
"""
        
        with open('README.md', 'w', encoding='utf-8') as f:
            f.write(readme_content)


# å‘½ä»¤è¡Œæ¥å£
def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å¹¿å‘Šè¿‡æ»¤è§„åˆ™ç”Ÿæˆå™¨ v3.0',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--mode', '-m',
        choices=['normal', 'strict', 'loose', 'enhanced'],
        default='normal',
        help='è¿è¡Œæ¨¡å¼: normal(é»˜è®¤), strict(ä¸¥æ ¼), loose(å®½æ¾), enhanced(å¢å¼º)'
    )
    
    parser.add_argument(
        '--config', '-c',
        default='config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '--output', '-o',
        help='è¾“å‡ºç›®å½•'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='è¯¦ç»†è¾“å‡º'
    )
    
    parser.add_argument(
        '--test', '-t',
        action='store_true',
        help='æµ‹è¯•æ¨¡å¼'
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # è¿è¡Œç”Ÿæˆå™¨
    generator = AdBlockGenerator(args.config)
    
    if args.test:
        # æµ‹è¯•æ¨¡å¼
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼è¿è¡Œä¸­...")
        success = generator.run('normal')
    else:
        # æ­£å¸¸æ¨¡å¼
        success = generator.run(args.mode)
    
    if success:
        print("âœ… è§„åˆ™ç”ŸæˆæˆåŠŸï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {generator.config.get('paths.outputs_dir')}")
        print("ğŸ“– æŸ¥çœ‹README.mdè·å–è®¢é˜…é“¾æ¥")
    else:
        print("âŒ è§„åˆ™ç”Ÿæˆå¤±è´¥ï¼")
        sys.exit(1)


if __name__ == "__main__":
    import sys
    main()
